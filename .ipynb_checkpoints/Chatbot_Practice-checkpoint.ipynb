{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "kkma = Kkma()\n",
    "\n",
    "text = \"아버지가 방에 들어갑니다.\"\n",
    "\n",
    "morphs = kkma.morphs(text)\n",
    "print(morphs)\n",
    "\n",
    "pos = kkma.pos(text)\n",
    "print(pos)\n",
    "\n",
    "nouns = kkma.nouns(text)\n",
    "print(nouns)\n",
    "\n",
    "sentences = \"오늘 날씨는 어때요? 내일은 덥다던데.\"\n",
    "s = kkma.sentences(sentences)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "text = \"아버지가 방에 들어갑니다.\"\n",
    "\n",
    "morphs = komoran.morphs(text)\n",
    "print(morphs)\n",
    "\n",
    "pos = komoran.pos(text)\n",
    "print(pos)\n",
    "\n",
    "nouns = komoran.nouns(text)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "text = \"서울의 기온은 매우 낮을 것입니다.\"\n",
    "\n",
    "morphs = okt.morphs(text)\n",
    "print(morphs)\n",
    "\n",
    "pos = okt.pos(text)\n",
    "print(pos)\n",
    "\n",
    "nouns = okt.nouns(text)\n",
    "print(nouns)\n",
    "\n",
    "text = \"와... 개쩐닼ㅋㅋㅋㅋ\"\n",
    "print(okt.normalize(text))\n",
    "print(okt.phrases(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran(userdic='./user_dic.tsv')\n",
    "text = \"우리 챗봇은 엔엘피를 좋아해\"\n",
    "pos = komoran.pos(text)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "\n",
    "komoran = Komoran()\n",
    "text = \"오늘 날씨는 구름이 많아요.\"\n",
    "\n",
    "nouns = komoran.nouns(text)\n",
    "print(nouns)\n",
    "\n",
    "dics = {}\n",
    "for word in nouns:\n",
    "    if word not in dics.keys():\n",
    "        dics[word] = len(dics)\n",
    "print(dics)\n",
    "\n",
    "nb_classes = len(dics)\n",
    "targets = list(dics.values())\n",
    "one_hot_targets = np.eye(nb_classes)[targets]\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 말뭉치 데이터 읽기 시작\n",
      "200000\n",
      "1) 말뭉치 데이터 읽기 완료 :  1.673100471496582\n",
      "2) 형태소에서 명사만 추출 시작\n",
      "2) 형태소에서 명사만 추출 완료 :  87.36483502388\n",
      "3) Word2Vec 모델 학습 시작\n",
      "3) Word2Vec 모델 학습 완료 :  105.85037922859192\n",
      "4) 학습된 모델 저장 시작\n",
      "4) 학습된 모델 저장 완료 :  106.3192617893219\n",
      "corpus_count :  200000\n",
      "corpus_total_words :  1076896\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Komoran\n",
    "import time\n",
    "\n",
    "def read_review_data(filename):\n",
    "    with open(filename, 'r', encoding=\"UTF8\") as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print('1) 말뭉치 데이터 읽기 시작')\n",
    "review_data = read_review_data('./ratings.txt')\n",
    "print(len(review_data))\n",
    "print('1) 말뭉치 데이터 읽기 완료 : ', time.time() - start)\n",
    "\n",
    "\n",
    "print('2) 형태소에서 명사만 추출 시작')\n",
    "komoran = Komoran()\n",
    "docs = [komoran.nouns(sentence[1]) for sentence in review_data]\n",
    "print('2) 형태소에서 명사만 추출 완료 : ', time.time() - start)\n",
    "\n",
    "print('3) Word2Vec 모델 학습 시작')\n",
    "model = Word2Vec(sentences=docs, size=200, window=4, hs=1, min_count=2, sg=1)\n",
    "print('3) Word2Vec 모델 학습 완료 : ', time.time() - start)\n",
    "\n",
    "print('4) 학습된 모델 저장 시작')\n",
    "model.save('nvmc.model')\n",
    "print('4) 학습된 모델 저장 완료 : ', time.time() - start)\n",
    "\n",
    "print(\"corpus_count : \", model.corpus_count)\n",
    "print(\"corpus_total_words : \", model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_total_words :  1076896\n",
      "사랑 :  [-2.18901098e-01 -2.30638266e-01 -3.23516726e-01 -1.10880509e-01\n",
      " -5.24657145e-02 -3.67247373e-01  2.49535859e-01 -1.10672571e-01\n",
      " -1.19900972e-01  5.35115078e-02 -4.20753807e-02 -1.63022757e-01\n",
      "  3.10032796e-02  5.87000251e-02  1.80825457e-01 -9.81938988e-02\n",
      "  1.56695947e-01  2.77327865e-01 -1.71590030e-01 -3.21360171e-01\n",
      " -1.89659074e-02  3.14504564e-01  1.14165783e-01 -9.37822089e-02\n",
      " -4.89308462e-02  1.42771974e-01  4.87611175e-01  2.64883310e-01\n",
      "  1.31326869e-01  6.54022321e-02 -5.31798825e-02  1.06777422e-01\n",
      " -3.57340509e-03  8.59801546e-02  2.35606715e-01 -1.58076987e-01\n",
      " -1.03374198e-02  1.60184503e-01 -5.67743219e-02 -1.14387959e-01\n",
      "  8.48006904e-02  1.62630752e-02  3.73258680e-01 -2.13345257e-03\n",
      "  1.42463073e-01 -3.05327505e-01 -4.06463087e-01 -9.46389064e-02\n",
      "  4.32475582e-02 -5.02498925e-01 -8.24670717e-02 -8.22420120e-02\n",
      " -1.53637022e-01  2.26479188e-01 -4.69100446e-01  4.85097691e-02\n",
      "  4.71878827e-01  1.51207283e-01  3.23728085e-01  1.01597108e-01\n",
      " -1.95750386e-01  1.86193481e-01 -3.19870800e-01  3.83708388e-01\n",
      "  2.13638037e-01 -1.16284043e-01 -2.05828428e-01  5.11621609e-02\n",
      "  2.84457564e-01 -1.56662643e-01 -3.30867708e-01 -8.49126950e-02\n",
      " -2.43772522e-01 -3.63577574e-01 -1.70495227e-01  1.03776492e-01\n",
      " -1.27607463e-02 -1.27620026e-01 -4.94027287e-02 -8.34354758e-02\n",
      " -3.70128155e-02 -2.16406241e-01 -2.92066664e-01 -1.34791620e-02\n",
      "  3.34517598e-01  9.53745991e-02  2.59860069e-01  6.94928244e-02\n",
      "  1.07402988e-01 -3.27572167e-01  3.35785262e-02  1.13541834e-01\n",
      "  1.37517780e-01  2.43552119e-01 -1.02563284e-01 -1.01520665e-01\n",
      "  1.22064367e-01 -1.39596105e-01  1.34276394e-02  1.53854797e-02\n",
      " -4.67230752e-03  1.27313375e-01 -2.46592805e-01 -1.96794406e-01\n",
      "  2.80651208e-02  1.66034758e-01  6.22787699e-02 -2.60984242e-01\n",
      " -1.42679047e-02  2.43712720e-02 -1.55180424e-01  4.61888701e-01\n",
      "  4.46382255e-05 -1.04882911e-01 -2.63523906e-01 -7.63684437e-02\n",
      "  2.56962448e-01 -3.21192831e-01  3.08848381e-01  1.62461415e-01\n",
      " -3.91210839e-02  1.10579856e-01  2.19921395e-01 -9.20721814e-02\n",
      "  3.10820788e-01 -3.99264783e-01  3.68805915e-01  9.43900943e-02\n",
      "  2.20943198e-01 -3.68393451e-01 -1.19109437e-01  1.34736523e-01\n",
      "  1.76278919e-01 -9.59831104e-02 -9.65517610e-02 -2.25214586e-02\n",
      "  6.06290437e-02  1.13153726e-01 -1.45290107e-01 -7.17325732e-02\n",
      "  1.07415833e-01 -1.63762420e-01 -2.93502212e-01 -9.64642614e-02\n",
      " -3.16201657e-01 -3.20466682e-02 -1.29419088e-01 -3.18060726e-01\n",
      "  1.80188149e-01  2.89177835e-01 -4.22630496e-02 -1.44796804e-01\n",
      " -2.88847238e-01  1.99350804e-01 -2.37252519e-01 -3.15522403e-01\n",
      "  2.27630496e-01 -1.62939390e-03 -3.98235649e-01  1.85395718e-01\n",
      "  9.63028818e-02 -7.66902789e-02 -2.18023703e-01  1.74231797e-01\n",
      " -8.22912380e-02 -6.50824681e-02  7.78316930e-02  1.42926857e-01\n",
      "  2.37267092e-01  9.61017236e-02  3.03372685e-02 -4.84025888e-02\n",
      "  2.28160441e-01 -2.74610996e-01 -6.05636165e-02  2.91774929e-01\n",
      "  4.64273505e-02 -3.32101822e-01  1.27709001e-01  3.28173377e-02\n",
      " -4.16574478e-01  1.40454143e-01  8.95205662e-02 -6.64288700e-02\n",
      "  3.02941710e-01 -1.56045958e-01  3.21986787e-02 -1.68491855e-01\n",
      "  8.31465945e-02  2.77149230e-02  2.01035142e-01  3.53935540e-01\n",
      "  2.69188851e-01  3.69968005e-02 -2.18224481e-01  1.86947539e-01\n",
      "  2.36695074e-02 -4.57510203e-02  1.91299453e-01  9.19692367e-02]\n",
      "일요일 = 월요일\t 0.6792425\n",
      "안성기 = 배우\t 0.58067536\n",
      "대기업 = 삼성\t 0.6054879\n",
      "일요일 != 삼성\t 0.2628131\n",
      "히어로 != 삼성\t 0.1367892\n",
      "[('씨야', 0.7127472162246704), ('장미희', 0.7094433307647705), ('고준희', 0.7018316984176636), ('김갑수', 0.7007349729537964), ('임원희', 0.6975858807563782), ('킬리언 머피', 0.6950335502624512), ('박중훈', 0.6948677897453308), ('정려원', 0.6947683095932007)]\n",
      "[('캐리비안의 해적', 0.6742691993713379), ('더 울버린', 0.6503077745437622), ('기사단', 0.644269585609436), ('엑스맨', 0.6423511505126953), ('데스티네이션', 0.6404320597648621), ('꽃보다 시리즈', 0.6390829682350159), ('X맨', 0.6337435245513916), ('러시아워', 0.6333252787590027)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('nvmc.model')\n",
    "print(\"corpus_total_words : \", model.corpus_total_words)\n",
    "\n",
    "print('사랑 : ', model.wv['사랑'])\n",
    "\n",
    "print(\"일요일 = 월요일\\t\", model.wv.similarity(w1='일요일', w2='월요일'))\n",
    "print(\"안성기 = 배우\\t\", model.wv.similarity(w1='안성기', w2='배우'))\n",
    "print(\"대기업 = 삼성\\t\", model.wv.similarity(w1='대기업', w2='삼성'))\n",
    "print(\"일요일 != 삼성\\t\", model.wv.similarity(w1='일요일', w2='삼성'))\n",
    "print(\"히어로 != 삼성\\t\", model.wv.similarity(w1='히어로', w2='삼성'))\n",
    "\n",
    "print(model.wv.most_similar(\"안성기\", topn=8))\n",
    "print(model.wv.most_similar(\"시리즈\", topn=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '트리니티'), ('트리니티', '입학'), ('입학',))\n",
      "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '대학교'), ('대학교', '입학'), ('입학',))\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "def word_ngram(bow, num_gram):\n",
    "    text = tuple(bow)\n",
    "    ngrams = [text[x:x + num_gram] for x in range(0, len(text))]\n",
    "    return tuple(ngrams)\n",
    "\n",
    "def similarity(doc1, doc2):\n",
    "    cnt = 0\n",
    "    for token in doc1:\n",
    "        if token in doc2:\n",
    "            cnt = cnt + 1\n",
    "        return cnt/len(doc1)\n",
    "\n",
    "sentence1 = '6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.'\n",
    "sentence2 = '6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.'\n",
    "sentence3 = '나는 맛있는 밥을 뉴턴 선생님과 함께 먹었다.'\n",
    "\n",
    "komoran = Komoran()\n",
    "bow1 = komoran.nouns(sentence1)\n",
    "bow2 = komoran.nouns(sentence2)\n",
    "bow3 = komoran.nouns(sentence3)\n",
    "\n",
    "doc1 = word_ngram(bow1, 2)\n",
    "doc2 = word_ngram(bow2, 2)\n",
    "doc3 = word_ngram(bow3, 2)\n",
    "\n",
    "print(doc1)\n",
    "print(doc2)\n",
    "\n",
    "r1 = similarity(doc1, doc2)\n",
    "r2 = similarity(doc3, doc1)\n",
    "\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 1, '입학': 1, '대학교': 0, '밥': 0, '선생': 0, '님과 함께': 0}\n",
      "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 0, '입학': 1, '대학교': 1, '밥': 0, '선생': 0, '님과 함께': 0}\n",
      "{'6월': 0, '뉴턴': 1, '선생님': 0, '제안': 0, '트리니티': 0, '입학': 0, '대학교': 0, '밥': 1, '선생': 1, '님과 함께': 1}\n",
      "0.8333333333333335\n",
      "0.20412414523193154\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(vec1, vec2):\n",
    "    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "def make_term_doc_mat(sentence_bow, word_dics):\n",
    "    freq_mat = {}\n",
    "    \n",
    "    for word in word_dics:\n",
    "        freq_mat[word] = 0\n",
    "        \n",
    "    for word in word_dics:\n",
    "        if word in sentence_bow:\n",
    "            freq_mat[word] += 1\n",
    "    \n",
    "    return freq_mat\n",
    "\n",
    "def make_vector(tdm):\n",
    "    vec = []\n",
    "    for key in tdm:\n",
    "        vec.append(tdm[key])\n",
    "    return vec\n",
    "\n",
    "sentence1 = '6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.'\n",
    "sentence2 = '6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.'\n",
    "sentence3 = '나는 맛있는 밥을 뉴턴 선생님과 함께 먹었다.'\n",
    "\n",
    "komoran = Komoran()\n",
    "bow1 = komoran.nouns(sentence1)\n",
    "bow2 = komoran.nouns(sentence2)\n",
    "bow3 = komoran.nouns(sentence3)\n",
    "\n",
    "bow = bow1 + bow2 + bow3\n",
    "\n",
    "word_dics = []\n",
    "for token in bow:\n",
    "    if token not in word_dics:\n",
    "        word_dics.append(token)\n",
    "\n",
    "freq_list1 = make_term_doc_mat(bow1, word_dics)\n",
    "freq_list2 = make_term_doc_mat(bow2, word_dics)\n",
    "freq_list3 = make_term_doc_mat(bow3, word_dics)\n",
    "print(freq_list1)\n",
    "print(freq_list2)\n",
    "print(freq_list3)\n",
    "\n",
    "doc1 = np.array(make_vector(freq_list1))\n",
    "doc2 = np.array(make_vector(freq_list2))\n",
    "doc3 = np.array(make_vector(freq_list3))\n",
    "\n",
    "r1 = cos_sim(doc1, doc2)\n",
    "r2 = cos_sim(doc3, doc1)\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2100/2100 [==============================] - 2s 917us/step - loss: 1.2659 - accuracy: 0.6049 - val_loss: 0.3759 - val_accuracy: 0.8920\n",
      "Epoch 2/10\n",
      "2100/2100 [==============================] - 2s 890us/step - loss: 0.3726 - accuracy: 0.8937 - val_loss: 0.3170 - val_accuracy: 0.9064\n",
      "Epoch 3/10\n",
      "2100/2100 [==============================] - 2s 876us/step - loss: 0.2952 - accuracy: 0.9157 - val_loss: 0.2604 - val_accuracy: 0.9253\n",
      "Epoch 4/10\n",
      "2100/2100 [==============================] - 2s 870us/step - loss: 0.2629 - accuracy: 0.9258 - val_loss: 0.2385 - val_accuracy: 0.9314\n",
      "Epoch 5/10\n",
      "2100/2100 [==============================] - 2s 872us/step - loss: 0.2296 - accuracy: 0.9350 - val_loss: 0.2242 - val_accuracy: 0.9368\n",
      "Epoch 6/10\n",
      "2100/2100 [==============================] - 2s 857us/step - loss: 0.2098 - accuracy: 0.9397 - val_loss: 0.2053 - val_accuracy: 0.9417\n",
      "Epoch 7/10\n",
      "2100/2100 [==============================] - 2s 862us/step - loss: 0.1964 - accuracy: 0.9432 - val_loss: 0.1886 - val_accuracy: 0.9471\n",
      "Epoch 8/10\n",
      "2100/2100 [==============================] - 2s 882us/step - loss: 0.1769 - accuracy: 0.9487 - val_loss: 0.1841 - val_accuracy: 0.9472\n",
      "Epoch 9/10\n",
      "2100/2100 [==============================] - 2s 848us/step - loss: 0.1688 - accuracy: 0.9518 - val_loss: 0.1695 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "2100/2100 [==============================] - 2s 881us/step - loss: 0.1627 - accuracy: 0.9525 - val_loss: 0.1643 - val_accuracy: 0.9532\n",
      "모델 평가\n",
      "313/313 [==============================] - 0s 604us/step - loss: 0.1714 - accuracy: 0.9500\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000)\n",
    "train_size = int(len(x_train) * 0.7)\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).batch(20)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#신경망 생성\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "#생선한 신경망을 학습\n",
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "print('모델 평가')\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 0s 393us/step - loss: 0.2028 - accuracy: 0.9402\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C717EC5F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "손글씨 이미지 예측값 :  [6]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "model = load_model('mnist_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "plt.imshow(x_test[100], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "picks = [100]\n",
    "predict = model.predict_classes(x_test[picks])\n",
    "print(\"손글씨 이미지 예측값 : \", predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "414/414 [==============================] - 7s 16ms/step - loss: 0.9938 - accuracy: 0.4627 - val_loss: 0.5985 - val_accuracy: 0.7885\n",
      "Epoch 2/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.5813 - accuracy: 0.7740 - val_loss: 0.2923 - val_accuracy: 0.8981\n",
      "Epoch 3/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.3348 - accuracy: 0.8891 - val_loss: 0.1549 - val_accuracy: 0.9564\n",
      "Epoch 4/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.2047 - accuracy: 0.9350 - val_loss: 0.0952 - val_accuracy: 0.9746\n",
      "Epoch 5/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.1307 - accuracy: 0.9595 - val_loss: 0.0720 - val_accuracy: 0.9746\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9873\n",
      "Accuracy: 98.730963 \n",
      "Loss: 0.055319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "\n",
    "train_file = \"./chatbot_data.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "features = data['Q'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "MAX_SEQ_LEN = 15\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "\n",
    "train_size = int(len(padded_seqs) * 0.7)\n",
    "val_size = int(len(padded_seqs) * 0.2)\n",
    "test_size = int(len(padded_seqs) * 0.1)\n",
    "\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size).take(test_size).batch(20)\n",
    "\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 5\n",
    "VOCAB_SIZE = len(word_index) + 1\n",
    "\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=3,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=4,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "concat = concatenate([pool1, pool2, pool3])\n",
    "\n",
    "hidden = Dense(128, activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(3, name='logits')(dropout_hidden)\n",
    "\n",
    "predictions = Dense(3, activation=tf.nn.softmax)(logits)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH)\n",
    "\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print('Accuracy: %f ' % (accuracy * 100))\n",
    "print('Loss: %f' % (loss))\n",
    "\n",
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 15, 128)      1715072     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 128)      0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 13, 128)      49280       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 12, 128)      65664       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 11, 128)      82048       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 128)          0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 128)          0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 384)          0           global_max_pooling1d_12[0][0]    \n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          49280       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "logits (Dense)                  (None, 3)            387         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 3)            12          logits[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,961,743\n",
      "Trainable params: 1,961,743\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "100/100 - 0s - loss: 0.0608 - accuracy: 0.9830\n",
      "단어 시퀀스 :  ['1지망', '학교', '떨어졌어']\n",
      "단어 인덱스 시퀀스 :  [4648  343  448    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "문장 분류(정답) :  0\n",
      "감정 예측 점수 :  [[9.9927360e-01 5.8017357e-04 1.4628886e-04]]\n",
      "감정 예측 클래스 :  [0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "train_file = \"./chatbot_data.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "features = data['Q'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "MAX_SEQ_LEN = 15\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "test_ds = ds.take(2000).batch(20)\n",
    "\n",
    "model = load_model('cnn_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(test_ds, verbose=2)\n",
    "\n",
    "print(\"단어 시퀀스 : \", corpus[1])\n",
    "print(\"단어 인덱스 시퀀스 : \", padded_seqs[1])\n",
    "print(\"문장 분류(정답) : \", labels[1])\n",
    "\n",
    "picks = [1]\n",
    "predict = model.predict(padded_seqs[picks])\n",
    "predict_class = tf.math.argmax(predict, axis=1)\n",
    "print(\"감정 예측 점수 : \", predict)\n",
    "print(\"감정 예측 클래스 : \", predict_class.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  x:(185, 15) / y:(185,)\n",
      "train_x.shape = (185, 15, 1)\n",
      "train_y.shape = (185,)\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.2017\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1290\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0685\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0305\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0271\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0231\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0189\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0130\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0113\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0053\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.6227e-04\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.1054e-04\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.7803e-04\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.2643e-04\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.5643e-04\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.2648e-04\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.7659e-04\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.9803e-04\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.4021e-04\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.9664e-04\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.3609e-04\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.7105e-04\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.6041e-04\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.6254e-04\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.3628e-04\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.7348e-04\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.0819e-04\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.0410e-04\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.5642e-04\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.6234e-04\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.5582e-04\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.2305e-04\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.2393e-04\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.9976e-04\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.1550e-04\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.7909e-04\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.9949e-04\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.6659e-04\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3687e-04\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3460e-04\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.4304e-04\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.4866e-04\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.3411e-04\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.4327e-04\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3422e-04\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.0017e-04\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.9592e-04\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.1081e-04\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.6771e-04\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.6165e-04\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.4656e-04\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.3261e-04\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.4428e-04\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.1803e-04\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1323e-04\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0996e-04\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.2584e-04\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0671e-04\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1172e-04\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8914e-04\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9185e-04\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9605e-04\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8028e-04\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.7246e-04\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.7538e-04\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6341e-04\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.5917e-04\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6415e-04\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5575e-04\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.5022e-04\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3696e-04\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3915e-04\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.4154e-04\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3866e-04\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2232e-04\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2820e-04\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1929e-04\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1469e-04\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1948e-04\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1163e-04\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1838e-04\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0712e-04\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.6761e-05\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0509e-04\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.6832e-05\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.9291e-05\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.8022e-05\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.4384e-05\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1613e-0 - 0s 1ms/step - loss: 9.9029e-05\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.0128e-05\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 8.4191e-05\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.7905e-05\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 8.7077e-05\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.1762e-05\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.4767e-05\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.9854e-05\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.1048e-05\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.3769e-05\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.5395e-05\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.4583e-05\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.5516e-05\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 6.9307e-0 - 0s 2ms/step - loss: 6.9411e-05\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.9849e-05\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.9947e-05\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.8854e-05\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.4913e-05\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.1752e-05\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.6468e-05\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.2013e-05\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.2216e-05\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.6141e-05\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.3358e-05\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.5314e-05\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.3821e-05\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.5464e-05\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.1635e-05\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.2844e-05\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.8686e-05\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.8991e-05\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.6626e-05\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.7315e-05\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.7194e-05\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.1419e-05\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.2951e-05\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3452e-05\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.1151e-05\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.1554e-05\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.9523e-05\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.8112e-05\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.8033e-05\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.7358e-05\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.7725e-05\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5793e-05\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5909e-05\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5311e-05\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5512e-05\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1595e-05\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.4367e-05\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.9869e-05\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.9132e-05\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.3030e-05\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0028e-05\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1427e-05\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8546e-05\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8408e-05\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9764e-05\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8038e-05\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9956e-05\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6587e-05\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8634e-05\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6018e-05\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5699e-05\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5292e-05\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5004e-05\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4037e-05\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4635e-05\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.2070e-05\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2639e-05\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3479e-05\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.6259e-05\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2268e-05\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3908e-05\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1663e-05\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1455e-05\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2289e-05\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1403e-05\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2231e-05\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1013e-05\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0240e-05\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0474e-05\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1740e-05\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1459e-05\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0834e-05\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0521e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM, SimpleRNN\n",
    "\n",
    "def split_sequence(sequence, step):\n",
    "    x, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        end_idx = i + step\n",
    "        if end_idx > len(sequence) - 1:\n",
    "            break\n",
    "            \n",
    "        seq_x, seq_y = sequence[i:end_idx], sequence[end_idx]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x = np.arange(start=-10, stop=10, step=0.1)\n",
    "train_y = [np.sin(i) for i in x]\n",
    "\n",
    "n_timesteps = 15\n",
    "n_features = 1\n",
    "\n",
    "train_x, train_y = split_sequence(train_y, step=n_timesteps)\n",
    "print(\"shape  x:{} / y:{}\".format(train_x.shape, train_y.shape))\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features)\n",
    "print(\"train_x.shape = {}\".format(train_x.shape))\n",
    "print(\"train_y.shape = {}\".format(train_y.shape))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=10, return_sequences=False, input_shape=(n_timesteps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, mode='auto')\n",
    "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping])\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "test_x = np.arange(10, 20, 0.1)\n",
    "calc_y = np.cos(test_x)\n",
    "\n",
    "test_y = calc_y[:n_timesteps]\n",
    "for i in range(len(test_x) - n_timesteps):\n",
    "    net_input = test_y[i : i + n_timesteps]\n",
    "    net_input = net_input.reshape((1, n_timesteps, n_features))\n",
    "    predict_y = model.predict(net_input)\n",
    "    test_y = np.append(test_y, predict_y)\n",
    "\n",
    "plt.plot(test_x, calc_y, label=\"ground truth\", color=\"orange\")\n",
    "plt.plot(test_x, test_y, label=\"prediction\", color=\"blue\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
