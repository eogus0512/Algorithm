{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "kkma = Kkma()\n",
    "\n",
    "text = \"아버지가 방에 들어갑니다.\"\n",
    "\n",
    "morphs = kkma.morphs(text)\n",
    "print(morphs)\n",
    "\n",
    "pos = kkma.pos(text)\n",
    "print(pos)\n",
    "\n",
    "nouns = kkma.nouns(text)\n",
    "print(nouns)\n",
    "\n",
    "sentences = \"오늘 날씨는 어때요? 내일은 덥다던데.\"\n",
    "s = kkma.sentences(sentences)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "text = \"아버지가 방에 들어갑니다.\"\n",
    "\n",
    "morphs = komoran.morphs(text)\n",
    "print(morphs)\n",
    "\n",
    "pos = komoran.pos(text)\n",
    "print(pos)\n",
    "\n",
    "nouns = komoran.nouns(text)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "text = \"서울의 기온은 매우 낮을 것입니다.\"\n",
    "\n",
    "morphs = okt.morphs(text)\n",
    "print(morphs)\n",
    "\n",
    "pos = okt.pos(text)\n",
    "print(pos)\n",
    "\n",
    "nouns = okt.nouns(text)\n",
    "print(nouns)\n",
    "\n",
    "text = \"와... 개쩐닼ㅋㅋㅋㅋ\"\n",
    "print(okt.normalize(text))\n",
    "print(okt.phrases(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran(userdic='./user_dic.tsv')\n",
    "text = \"우리 챗봇은 엔엘피를 좋아해\"\n",
    "pos = komoran.pos(text)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "\n",
    "komoran = Komoran()\n",
    "text = \"오늘 날씨는 구름이 많아요.\"\n",
    "\n",
    "nouns = komoran.nouns(text)\n",
    "print(nouns)\n",
    "\n",
    "dics = {}\n",
    "for word in nouns:\n",
    "    if word not in dics.keys():\n",
    "        dics[word] = len(dics)\n",
    "print(dics)\n",
    "\n",
    "nb_classes = len(dics)\n",
    "targets = list(dics.values())\n",
    "one_hot_targets = np.eye(nb_classes)[targets]\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 말뭉치 데이터 읽기 시작\n",
      "200000\n",
      "1) 말뭉치 데이터 읽기 완료 :  1.673100471496582\n",
      "2) 형태소에서 명사만 추출 시작\n",
      "2) 형태소에서 명사만 추출 완료 :  87.36483502388\n",
      "3) Word2Vec 모델 학습 시작\n",
      "3) Word2Vec 모델 학습 완료 :  105.85037922859192\n",
      "4) 학습된 모델 저장 시작\n",
      "4) 학습된 모델 저장 완료 :  106.3192617893219\n",
      "corpus_count :  200000\n",
      "corpus_total_words :  1076896\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Komoran\n",
    "import time\n",
    "\n",
    "def read_review_data(filename):\n",
    "    with open(filename, 'r', encoding=\"UTF8\") as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print('1) 말뭉치 데이터 읽기 시작')\n",
    "review_data = read_review_data('./ratings.txt')\n",
    "print(len(review_data))\n",
    "print('1) 말뭉치 데이터 읽기 완료 : ', time.time() - start)\n",
    "\n",
    "\n",
    "print('2) 형태소에서 명사만 추출 시작')\n",
    "komoran = Komoran()\n",
    "docs = [komoran.nouns(sentence[1]) for sentence in review_data]\n",
    "print('2) 형태소에서 명사만 추출 완료 : ', time.time() - start)\n",
    "\n",
    "print('3) Word2Vec 모델 학습 시작')\n",
    "model = Word2Vec(sentences=docs, size=200, window=4, hs=1, min_count=2, sg=1)\n",
    "print('3) Word2Vec 모델 학습 완료 : ', time.time() - start)\n",
    "\n",
    "print('4) 학습된 모델 저장 시작')\n",
    "model.save('nvmc.model')\n",
    "print('4) 학습된 모델 저장 완료 : ', time.time() - start)\n",
    "\n",
    "print(\"corpus_count : \", model.corpus_count)\n",
    "print(\"corpus_total_words : \", model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_total_words :  1076896\n",
      "사랑 :  [-2.18901098e-01 -2.30638266e-01 -3.23516726e-01 -1.10880509e-01\n",
      " -5.24657145e-02 -3.67247373e-01  2.49535859e-01 -1.10672571e-01\n",
      " -1.19900972e-01  5.35115078e-02 -4.20753807e-02 -1.63022757e-01\n",
      "  3.10032796e-02  5.87000251e-02  1.80825457e-01 -9.81938988e-02\n",
      "  1.56695947e-01  2.77327865e-01 -1.71590030e-01 -3.21360171e-01\n",
      " -1.89659074e-02  3.14504564e-01  1.14165783e-01 -9.37822089e-02\n",
      " -4.89308462e-02  1.42771974e-01  4.87611175e-01  2.64883310e-01\n",
      "  1.31326869e-01  6.54022321e-02 -5.31798825e-02  1.06777422e-01\n",
      " -3.57340509e-03  8.59801546e-02  2.35606715e-01 -1.58076987e-01\n",
      " -1.03374198e-02  1.60184503e-01 -5.67743219e-02 -1.14387959e-01\n",
      "  8.48006904e-02  1.62630752e-02  3.73258680e-01 -2.13345257e-03\n",
      "  1.42463073e-01 -3.05327505e-01 -4.06463087e-01 -9.46389064e-02\n",
      "  4.32475582e-02 -5.02498925e-01 -8.24670717e-02 -8.22420120e-02\n",
      " -1.53637022e-01  2.26479188e-01 -4.69100446e-01  4.85097691e-02\n",
      "  4.71878827e-01  1.51207283e-01  3.23728085e-01  1.01597108e-01\n",
      " -1.95750386e-01  1.86193481e-01 -3.19870800e-01  3.83708388e-01\n",
      "  2.13638037e-01 -1.16284043e-01 -2.05828428e-01  5.11621609e-02\n",
      "  2.84457564e-01 -1.56662643e-01 -3.30867708e-01 -8.49126950e-02\n",
      " -2.43772522e-01 -3.63577574e-01 -1.70495227e-01  1.03776492e-01\n",
      " -1.27607463e-02 -1.27620026e-01 -4.94027287e-02 -8.34354758e-02\n",
      " -3.70128155e-02 -2.16406241e-01 -2.92066664e-01 -1.34791620e-02\n",
      "  3.34517598e-01  9.53745991e-02  2.59860069e-01  6.94928244e-02\n",
      "  1.07402988e-01 -3.27572167e-01  3.35785262e-02  1.13541834e-01\n",
      "  1.37517780e-01  2.43552119e-01 -1.02563284e-01 -1.01520665e-01\n",
      "  1.22064367e-01 -1.39596105e-01  1.34276394e-02  1.53854797e-02\n",
      " -4.67230752e-03  1.27313375e-01 -2.46592805e-01 -1.96794406e-01\n",
      "  2.80651208e-02  1.66034758e-01  6.22787699e-02 -2.60984242e-01\n",
      " -1.42679047e-02  2.43712720e-02 -1.55180424e-01  4.61888701e-01\n",
      "  4.46382255e-05 -1.04882911e-01 -2.63523906e-01 -7.63684437e-02\n",
      "  2.56962448e-01 -3.21192831e-01  3.08848381e-01  1.62461415e-01\n",
      " -3.91210839e-02  1.10579856e-01  2.19921395e-01 -9.20721814e-02\n",
      "  3.10820788e-01 -3.99264783e-01  3.68805915e-01  9.43900943e-02\n",
      "  2.20943198e-01 -3.68393451e-01 -1.19109437e-01  1.34736523e-01\n",
      "  1.76278919e-01 -9.59831104e-02 -9.65517610e-02 -2.25214586e-02\n",
      "  6.06290437e-02  1.13153726e-01 -1.45290107e-01 -7.17325732e-02\n",
      "  1.07415833e-01 -1.63762420e-01 -2.93502212e-01 -9.64642614e-02\n",
      " -3.16201657e-01 -3.20466682e-02 -1.29419088e-01 -3.18060726e-01\n",
      "  1.80188149e-01  2.89177835e-01 -4.22630496e-02 -1.44796804e-01\n",
      " -2.88847238e-01  1.99350804e-01 -2.37252519e-01 -3.15522403e-01\n",
      "  2.27630496e-01 -1.62939390e-03 -3.98235649e-01  1.85395718e-01\n",
      "  9.63028818e-02 -7.66902789e-02 -2.18023703e-01  1.74231797e-01\n",
      " -8.22912380e-02 -6.50824681e-02  7.78316930e-02  1.42926857e-01\n",
      "  2.37267092e-01  9.61017236e-02  3.03372685e-02 -4.84025888e-02\n",
      "  2.28160441e-01 -2.74610996e-01 -6.05636165e-02  2.91774929e-01\n",
      "  4.64273505e-02 -3.32101822e-01  1.27709001e-01  3.28173377e-02\n",
      " -4.16574478e-01  1.40454143e-01  8.95205662e-02 -6.64288700e-02\n",
      "  3.02941710e-01 -1.56045958e-01  3.21986787e-02 -1.68491855e-01\n",
      "  8.31465945e-02  2.77149230e-02  2.01035142e-01  3.53935540e-01\n",
      "  2.69188851e-01  3.69968005e-02 -2.18224481e-01  1.86947539e-01\n",
      "  2.36695074e-02 -4.57510203e-02  1.91299453e-01  9.19692367e-02]\n",
      "일요일 = 월요일\t 0.6792425\n",
      "안성기 = 배우\t 0.58067536\n",
      "대기업 = 삼성\t 0.6054879\n",
      "일요일 != 삼성\t 0.2628131\n",
      "히어로 != 삼성\t 0.1367892\n",
      "[('씨야', 0.7127472162246704), ('장미희', 0.7094433307647705), ('고준희', 0.7018316984176636), ('김갑수', 0.7007349729537964), ('임원희', 0.6975858807563782), ('킬리언 머피', 0.6950335502624512), ('박중훈', 0.6948677897453308), ('정려원', 0.6947683095932007)]\n",
      "[('캐리비안의 해적', 0.6742691993713379), ('더 울버린', 0.6503077745437622), ('기사단', 0.644269585609436), ('엑스맨', 0.6423511505126953), ('데스티네이션', 0.6404320597648621), ('꽃보다 시리즈', 0.6390829682350159), ('X맨', 0.6337435245513916), ('러시아워', 0.6333252787590027)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load('nvmc.model')\n",
    "print(\"corpus_total_words : \", model.corpus_total_words)\n",
    "\n",
    "print('사랑 : ', model.wv['사랑'])\n",
    "\n",
    "print(\"일요일 = 월요일\\t\", model.wv.similarity(w1='일요일', w2='월요일'))\n",
    "print(\"안성기 = 배우\\t\", model.wv.similarity(w1='안성기', w2='배우'))\n",
    "print(\"대기업 = 삼성\\t\", model.wv.similarity(w1='대기업', w2='삼성'))\n",
    "print(\"일요일 != 삼성\\t\", model.wv.similarity(w1='일요일', w2='삼성'))\n",
    "print(\"히어로 != 삼성\\t\", model.wv.similarity(w1='히어로', w2='삼성'))\n",
    "\n",
    "print(model.wv.most_similar(\"안성기\", topn=8))\n",
    "print(model.wv.most_similar(\"시리즈\", topn=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '트리니티'), ('트리니티', '입학'), ('입학',))\n",
      "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '대학교'), ('대학교', '입학'), ('입학',))\n",
      "0.16666666666666666\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "def word_ngram(bow, num_gram):\n",
    "    text = tuple(bow)\n",
    "    ngrams = [text[x:x + num_gram] for x in range(0, len(text))]\n",
    "    return tuple(ngrams)\n",
    "\n",
    "def similarity(doc1, doc2):\n",
    "    cnt = 0\n",
    "    for token in doc1:\n",
    "        if token in doc2:\n",
    "            cnt = cnt + 1\n",
    "        return cnt/len(doc1)\n",
    "\n",
    "sentence1 = '6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.'\n",
    "sentence2 = '6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.'\n",
    "sentence3 = '나는 맛있는 밥을 뉴턴 선생님과 함께 먹었다.'\n",
    "\n",
    "komoran = Komoran()\n",
    "bow1 = komoran.nouns(sentence1)\n",
    "bow2 = komoran.nouns(sentence2)\n",
    "bow3 = komoran.nouns(sentence3)\n",
    "\n",
    "doc1 = word_ngram(bow1, 2)\n",
    "doc2 = word_ngram(bow2, 2)\n",
    "doc3 = word_ngram(bow3, 2)\n",
    "\n",
    "print(doc1)\n",
    "print(doc2)\n",
    "\n",
    "r1 = similarity(doc1, doc2)\n",
    "r2 = similarity(doc3, doc1)\n",
    "\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 1, '입학': 1, '대학교': 0, '밥': 0, '선생': 0, '님과 함께': 0}\n",
      "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 0, '입학': 1, '대학교': 1, '밥': 0, '선생': 0, '님과 함께': 0}\n",
      "{'6월': 0, '뉴턴': 1, '선생님': 0, '제안': 0, '트리니티': 0, '입학': 0, '대학교': 0, '밥': 1, '선생': 1, '님과 함께': 1}\n",
      "0.8333333333333335\n",
      "0.20412414523193154\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(vec1, vec2):\n",
    "    return dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "def make_term_doc_mat(sentence_bow, word_dics):\n",
    "    freq_mat = {}\n",
    "    \n",
    "    for word in word_dics:\n",
    "        freq_mat[word] = 0\n",
    "        \n",
    "    for word in word_dics:\n",
    "        if word in sentence_bow:\n",
    "            freq_mat[word] += 1\n",
    "    \n",
    "    return freq_mat\n",
    "\n",
    "def make_vector(tdm):\n",
    "    vec = []\n",
    "    for key in tdm:\n",
    "        vec.append(tdm[key])\n",
    "    return vec\n",
    "\n",
    "sentence1 = '6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.'\n",
    "sentence2 = '6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.'\n",
    "sentence3 = '나는 맛있는 밥을 뉴턴 선생님과 함께 먹었다.'\n",
    "\n",
    "komoran = Komoran()\n",
    "bow1 = komoran.nouns(sentence1)\n",
    "bow2 = komoran.nouns(sentence2)\n",
    "bow3 = komoran.nouns(sentence3)\n",
    "\n",
    "bow = bow1 + bow2 + bow3\n",
    "\n",
    "word_dics = []\n",
    "for token in bow:\n",
    "    if token not in word_dics:\n",
    "        word_dics.append(token)\n",
    "\n",
    "freq_list1 = make_term_doc_mat(bow1, word_dics)\n",
    "freq_list2 = make_term_doc_mat(bow2, word_dics)\n",
    "freq_list3 = make_term_doc_mat(bow3, word_dics)\n",
    "print(freq_list1)\n",
    "print(freq_list2)\n",
    "print(freq_list3)\n",
    "\n",
    "doc1 = np.array(make_vector(freq_list1))\n",
    "doc2 = np.array(make_vector(freq_list2))\n",
    "doc3 = np.array(make_vector(freq_list3))\n",
    "\n",
    "r1 = cos_sim(doc1, doc2)\n",
    "r2 = cos_sim(doc3, doc1)\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2100/2100 [==============================] - 2s 917us/step - loss: 1.2659 - accuracy: 0.6049 - val_loss: 0.3759 - val_accuracy: 0.8920\n",
      "Epoch 2/10\n",
      "2100/2100 [==============================] - 2s 890us/step - loss: 0.3726 - accuracy: 0.8937 - val_loss: 0.3170 - val_accuracy: 0.9064\n",
      "Epoch 3/10\n",
      "2100/2100 [==============================] - 2s 876us/step - loss: 0.2952 - accuracy: 0.9157 - val_loss: 0.2604 - val_accuracy: 0.9253\n",
      "Epoch 4/10\n",
      "2100/2100 [==============================] - 2s 870us/step - loss: 0.2629 - accuracy: 0.9258 - val_loss: 0.2385 - val_accuracy: 0.9314\n",
      "Epoch 5/10\n",
      "2100/2100 [==============================] - 2s 872us/step - loss: 0.2296 - accuracy: 0.9350 - val_loss: 0.2242 - val_accuracy: 0.9368\n",
      "Epoch 6/10\n",
      "2100/2100 [==============================] - 2s 857us/step - loss: 0.2098 - accuracy: 0.9397 - val_loss: 0.2053 - val_accuracy: 0.9417\n",
      "Epoch 7/10\n",
      "2100/2100 [==============================] - 2s 862us/step - loss: 0.1964 - accuracy: 0.9432 - val_loss: 0.1886 - val_accuracy: 0.9471\n",
      "Epoch 8/10\n",
      "2100/2100 [==============================] - 2s 882us/step - loss: 0.1769 - accuracy: 0.9487 - val_loss: 0.1841 - val_accuracy: 0.9472\n",
      "Epoch 9/10\n",
      "2100/2100 [==============================] - 2s 848us/step - loss: 0.1688 - accuracy: 0.9518 - val_loss: 0.1695 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "2100/2100 [==============================] - 2s 881us/step - loss: 0.1627 - accuracy: 0.9525 - val_loss: 0.1643 - val_accuracy: 0.9532\n",
      "모델 평가\n",
      "313/313 [==============================] - 0s 604us/step - loss: 0.1714 - accuracy: 0.9500\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000)\n",
    "train_size = int(len(x_train) * 0.7)\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).batch(20)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#신경망 생성\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "#생선한 신경망을 학습\n",
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "print('모델 평가')\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.save('mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 16,330\n",
      "Trainable params: 16,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 0s 393us/step - loss: 0.2028 - accuracy: 0.9402\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C717EC5F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "손글씨 이미지 예측값 :  [6]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "model = load_model('mnist_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "plt.imshow(x_test[100], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "picks = [100]\n",
    "predict = model.predict_classes(x_test[picks])\n",
    "print(\"손글씨 이미지 예측값 : \", predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "414/414 [==============================] - 7s 16ms/step - loss: 0.9938 - accuracy: 0.4627 - val_loss: 0.5985 - val_accuracy: 0.7885\n",
      "Epoch 2/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.5813 - accuracy: 0.7740 - val_loss: 0.2923 - val_accuracy: 0.8981\n",
      "Epoch 3/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.3348 - accuracy: 0.8891 - val_loss: 0.1549 - val_accuracy: 0.9564\n",
      "Epoch 4/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.2047 - accuracy: 0.9350 - val_loss: 0.0952 - val_accuracy: 0.9746\n",
      "Epoch 5/5\n",
      "414/414 [==============================] - 6s 15ms/step - loss: 0.1307 - accuracy: 0.9595 - val_loss: 0.0720 - val_accuracy: 0.9746\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9873\n",
      "Accuracy: 98.730963 \n",
      "Loss: 0.055319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "\n",
    "train_file = \"./chatbot_data.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "features = data['Q'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "MAX_SEQ_LEN = 15\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "\n",
    "train_size = int(len(padded_seqs) * 0.7)\n",
    "val_size = int(len(padded_seqs) * 0.2)\n",
    "test_size = int(len(padded_seqs) * 0.1)\n",
    "\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size).take(test_size).batch(20)\n",
    "\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 5\n",
    "VOCAB_SIZE = len(word_index) + 1\n",
    "\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=3,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=4,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "concat = concatenate([pool1, pool2, pool3])\n",
    "\n",
    "hidden = Dense(128, activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(3, name='logits')(dropout_hidden)\n",
    "\n",
    "predictions = Dense(3, activation=tf.nn.softmax)(logits)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH)\n",
    "\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print('Accuracy: %f ' % (accuracy * 100))\n",
    "print('Loss: %f' % (loss))\n",
    "\n",
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 15, 128)      1715072     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 128)      0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 13, 128)      49280       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 12, 128)      65664       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 11, 128)      82048       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 128)          0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 128)          0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 128)          0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 384)          0           global_max_pooling1d_12[0][0]    \n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          49280       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "logits (Dense)                  (None, 3)            387         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 3)            12          logits[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,961,743\n",
      "Trainable params: 1,961,743\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "100/100 - 0s - loss: 0.0608 - accuracy: 0.9830\n",
      "단어 시퀀스 :  ['1지망', '학교', '떨어졌어']\n",
      "단어 인덱스 시퀀스 :  [4648  343  448    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "문장 분류(정답) :  0\n",
      "감정 예측 점수 :  [[9.9927360e-01 5.8017357e-04 1.4628886e-04]]\n",
      "감정 예측 클래스 :  [0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "train_file = \"./chatbot_data.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "features = data['Q'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "MAX_SEQ_LEN = 15\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "test_ds = ds.take(2000).batch(20)\n",
    "\n",
    "model = load_model('cnn_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(test_ds, verbose=2)\n",
    "\n",
    "print(\"단어 시퀀스 : \", corpus[1])\n",
    "print(\"단어 인덱스 시퀀스 : \", padded_seqs[1])\n",
    "print(\"문장 분류(정답) : \", labels[1])\n",
    "\n",
    "picks = [1]\n",
    "predict = model.predict(padded_seqs[picks])\n",
    "predict_class = tf.math.argmax(predict, axis=1)\n",
    "print(\"감정 예측 점수 : \", predict)\n",
    "print(\"감정 예측 클래스 : \", predict_class.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  x:(185, 15) / y:(185,)\n",
      "train_x.shape = (185, 15, 1)\n",
      "train_y.shape = (185,)\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.2017\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1290\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0685\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0305\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0271\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0231\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0189\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0130\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0113\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0053\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0044\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.6227e-04\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.1054e-04\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.7803e-04\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.2643e-04\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.5643e-04\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.2648e-04\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.7659e-04\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.9803e-04\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.4021e-04\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.9664e-04\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.3609e-04\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.7105e-04\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.6041e-04\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.6254e-04\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.3628e-04\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.7348e-04\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.0819e-04\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.0410e-04\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.5642e-04\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.6234e-04\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.5582e-04\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.2305e-04\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.2393e-04\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.9976e-04\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.1550e-04\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.7909e-04\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.9949e-04\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.6659e-04\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3687e-04\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3460e-04\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.4304e-04\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.4866e-04\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.3411e-04\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.4327e-04\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3422e-04\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.0017e-04\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.9592e-04\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.1081e-04\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.6771e-04\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.6165e-04\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.4656e-04\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.3261e-04\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.4428e-04\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.1803e-04\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1323e-04\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0996e-04\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.2584e-04\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0671e-04\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1172e-04\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8914e-04\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9185e-04\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9605e-04\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8028e-04\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.7246e-04\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.7538e-04\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6341e-04\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.5917e-04\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6415e-04\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5575e-04\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.5022e-04\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3696e-04\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3915e-04\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.4154e-04\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3866e-04\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2232e-04\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2820e-04\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1929e-04\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1469e-04\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1948e-04\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1163e-04\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1838e-04\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0712e-04\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.6761e-05\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0509e-04\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.6832e-05\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.9291e-05\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.8022e-05\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 9.4384e-05\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1613e-0 - 0s 1ms/step - loss: 9.9029e-05\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 9.0128e-05\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 8.4191e-05\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.7905e-05\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 8.7077e-05\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 8.1762e-05\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.4767e-05\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.9854e-05\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 7.1048e-05\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 7.3769e-05\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.5395e-05\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 6.4583e-05\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.5516e-05\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 6.9307e-0 - 0s 2ms/step - loss: 6.9411e-05\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.9849e-05\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.9947e-05\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.8854e-05\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.4913e-05\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.1752e-05\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.6468e-05\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 5.2013e-05\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.2216e-05\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.6141e-05\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.3358e-05\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.5314e-05\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.3821e-05\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 4.5464e-05\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.1635e-05\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 4.2844e-05\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.8686e-05\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.8991e-05\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.6626e-05\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.7315e-05\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.7194e-05\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.1419e-05\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.2951e-05\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.3452e-05\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.1151e-05\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 3.1554e-05\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.9523e-05\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.8112e-05\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.8033e-05\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.7358e-05\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.7725e-05\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5793e-05\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5909e-05\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5311e-05\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.5512e-05\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1595e-05\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.4367e-05\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.9869e-05\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.9132e-05\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.3030e-05\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0028e-05\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1427e-05\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8546e-05\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8408e-05\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9764e-05\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8038e-05\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9956e-05\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6587e-05\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8634e-05\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6018e-05\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5699e-05\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5292e-05\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5004e-05\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4037e-05\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4635e-05\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.2070e-05\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2639e-05\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3479e-05\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.6259e-05\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2268e-05\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3908e-05\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1663e-05\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1455e-05\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2289e-05\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1403e-05\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2231e-05\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1013e-05\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0240e-05\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0474e-05\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1740e-05\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.1459e-05\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0834e-05\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0521e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM, SimpleRNN\n",
    "\n",
    "def split_sequence(sequence, step):\n",
    "    x, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        end_idx = i + step\n",
    "        if end_idx > len(sequence) - 1:\n",
    "            break\n",
    "            \n",
    "        seq_x, seq_y = sequence[i:end_idx], sequence[end_idx]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x = np.arange(start=-10, stop=10, step=0.1)\n",
    "train_y = [np.sin(i) for i in x]\n",
    "\n",
    "n_timesteps = 15\n",
    "n_features = 1\n",
    "\n",
    "train_x, train_y = split_sequence(train_y, step=n_timesteps)\n",
    "print(\"shape  x:{} / y:{}\".format(train_x.shape, train_y.shape))\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features)\n",
    "print(\"train_x.shape = {}\".format(train_x.shape))\n",
    "print(\"train_y.shape = {}\".format(train_y.shape))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=10, return_sequences=False, input_shape=(n_timesteps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, mode='auto')\n",
    "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping])\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "test_x = np.arange(10, 20, 0.1)\n",
    "calc_y = np.cos(test_x)\n",
    "\n",
    "test_y = calc_y[:n_timesteps]\n",
    "for i in range(len(test_x) - n_timesteps):\n",
    "    net_input = test_y[i : i + n_timesteps]\n",
    "    net_input = net_input.reshape((1, n_timesteps, n_features))\n",
    "    predict_y = model.predict(net_input)\n",
    "    test_y = np.append(test_y, predict_y)\n",
    "\n",
    "plt.plot(test_x, calc_y, label=\"ground truth\", color=\"orange\")\n",
    "plt.plot(test_x, test_y, label=\"prediction\", color=\"blue\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  x:(185, 15) / y:(185,)\n",
      "[[ 0.54402111  0.45753589  0.36647913 ... -0.58491719 -0.66296923\n",
      "  -0.7343971 ]\n",
      " [ 0.45753589  0.36647913  0.27176063 ... -0.66296923 -0.7343971\n",
      "  -0.79848711]\n",
      " [ 0.36647913  0.27176063  0.17432678 ... -0.7343971  -0.79848711\n",
      "  -0.85459891]\n",
      " ...\n",
      " [ 0.94073056  0.90217183  0.85459891 ...  0.02477543 -0.07515112\n",
      "  -0.17432678]\n",
      " [ 0.90217183  0.85459891  0.79848711 ... -0.07515112 -0.17432678\n",
      "  -0.27176063]\n",
      " [ 0.85459891  0.79848711  0.7343971  ... -0.17432678 -0.27176063\n",
      "  -0.36647913]]\n",
      "train_x.shape = (185, 15, 1)\n",
      "train_y.shape = (185,)\n",
      "Epoch 1/1000\n",
      "6/6 [==============================] - 2s 4ms/step - loss: 0.2505\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2204\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1847\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1646\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1380\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1227\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0991\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0866\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0797\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0770\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0648\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0650\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0632\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0518\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0438\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0397\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0351\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0296\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0242\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0170\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0131\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0108\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0097\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0052\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.8586e-04\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.0947e-04\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.1379e-04\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.7844e-04\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.2497e-04\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.0675e-04\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.1503e-04\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.7124e-04\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.8576e-04\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.7183e-04\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.6452e-04\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.1815e-04\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.1312e-04\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.6051e-04\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.8547e-04\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.8764e-04\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.8337e-04\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.6774e-04\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.5968e-04\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.6344e-04\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.1423e-04\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.2241e-04\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.3453e-0 - 0s 3ms/step - loss: 3.7264e-04\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.6451e-04\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.5034e-04\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.4859e-04\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.1847e-04\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.9900e-04\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.1934e-04\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.8725e-04\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.0136e-04\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.8252e-04\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.5614e-04\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.4108e-04\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.3038e-04\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.1114e-04\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.1786e-04\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.2635e-04\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.1692e-04\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.8813e-04\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.9859e-04\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.8394e-04\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7316e-04\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7671e-04\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6768e-04\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5095e-04\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5872e-04\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5545e-04\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4611e-04\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5092e-04\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4483e-04\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2706e-04\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3313e-04\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1971e-04\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2892e-04\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2369e-04\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1357e-04\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1575e-04\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1432e-04\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1091e-04\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.8856e-05\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.1876e-05\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.3483e-05\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.3539e-05\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 8.9991e-0 - 0s 3ms/step - loss: 8.8029e-05\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.3024e-05\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.0034e-05\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.8262e-05\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.6070e-05\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.2242e-05\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.1131e-05\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.5696e-05\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.6179e-05\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.9927e-05\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.8485e-05\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.8441e-05\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.3785e-05\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.1843e-05\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.0169e-05\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.9415e-05\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.0157e-05\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.4412e-05\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.7752e-05\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.5149e-05\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.1087e-05\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.0433e-05\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.1780e-05\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.2079e-05\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.6903e-05\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.1765e-05\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.7630e-05\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.5934e-05\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.2206e-05\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.4787e-05\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.1187e-05\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4.2211e-05\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.8845e-05\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.8268e-05\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.8700e-05\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.8066e-05\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.4288e-05\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.3077e-05\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.4354e-05\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.3488e-05\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.4318e-05\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.1064e-05\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.7429e-05\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.2222e-05\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.0819e-0 - 0s 3ms/step - loss: 3.0490e-05\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.1679e-05\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.7475e-05\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.6091e-05\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.9673e-05\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.4419e-05\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.7272e-05\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.5639e-05\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.4367e-05\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.4774e-05\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.3414e-05\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.2065e-05\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.3086e-05\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.3184e-05\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.1197e-05\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.0754e-05\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.2860e-05\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.1668e-05\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.9595e-05\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.0512e-05\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.0160e-05\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7096e-05\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7550e-05\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7680e-05\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.9019e-05\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7709e-05\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5344e-05\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5920e-05\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4735e-05\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5741e-05\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6805e-05\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3784e-05\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4325e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5628e-05\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4791e-05\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3965e-05\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4244e-05\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4520e-05\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4668e-05\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4078e-05\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2351e-05\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3439e-05\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3165e-05\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3389e-05\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0896e-05\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2285e-05\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2607e-05\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0421e-05\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.9818e-06\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1417e-05\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.7758e-06\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0997e-05\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0073e-05\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0391e-05\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.7608e-06\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.9043e-06\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.3949e-06\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0509e-05\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.5051e-06\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.1378e-06\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.4457e-06\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.0942e-06\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.0296e-06\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.4604e-06\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.0608e-06\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.6605e-06\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9.4272e-06\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.5864e-06\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.1687e-06\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.8172e-06\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.5040e-06\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.3012e-06\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8.1518e-06\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.6803e-06\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.5436e-06\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.4204e-06\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.6525e-06\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.3695e-06\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.0625e-06\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.0851e-06\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.4068e-06\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.5697e-06\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.0726e-06\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.1667e-06\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.2707e-06\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.7539e-06\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.1631e-06\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.1330e-06\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.6859e-06\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.5951e-06\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.7967e-06\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.4096e-06\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.4115e-06\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.2735e-06\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.6729e-06\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.5682e-06\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.4650e-06\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.3759e-06\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.9089e-06\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6.1461e-06\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 5.8363e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyPElEQVR4nO3dd3gU5drH8e+dAoFQpPeq9F6kNwuKgiCICueoKGoEEQERDuJRBCyo2KiKDVTEoyKKgAJSBESE0FuAAAFCT2iJkH6/fyTyIiaEkM1Odvf+XNde2d2ZzPObBO7MzjzzPKKqGGOM8X5+TgcwxhjjHlbwjTHGR1jBN8YYH2EF3xhjfIQVfGOM8RFW8I0xxkdku+CLSAURWSYiO0Vku4gMSmcdEZEJIhIuIltEpHF22zXGGJM1AS7YRhIwVFU3iEhBYL2ILFbVHZescwdQLe3RHJia9tUYY4ybZPsIX1WPquqGtOcxwE6g3GWrdQM+01RrgOtEpEx22zbGGHP1XHGEf5GIVAYaAX9ctqgccOiS15Fp7x1NZxshQAhAcHBwk5o1a7oyojHGeLX169dHqWqJ9Ja5rOCLSAFgNjBYVc9dvjidb0l3TAdVnQZMA2jatKmGhoa6KqIxxng9ETmQ0TKX9NIRkUBSi/1MVf0unVUigQqXvC4PHHFF28YYY66OK3rpCPAxsFNV385gtbnAQ2m9dVoAZ1X1H6dzjDHG5BxXnNJpDTwIbBWRTWnvjQQqAqjq+8AC4E4gHDgPPOKCdo0xxmRBtgu+qq4i/XP0l66jwIDstgWQmJhIZGQkcXFxrticuUZBQUGUL1+ewMBAp6MYY66SS3vpuENkZCQFCxakcuXKpJ5NMu6mqkRHRxMZGUmVKlWcjmOMuUoeN7RCXFwcxYoVs2LvIBGhWLFi9inLGA/jcQUfsGKfC9jvwBjP45EF3xhjTNZZwfdAL730EuPHj//H+99//z07duxI5zuuLCIigi+//PLi6+nTp/PUU09lK6MxJvexgp9DkpKS3N7mlQr+lfJcXvCNMd7JCv41GDt2LDVr1qRjx4707t374tF2hw4dGDlyJO3bt+e9995jyZIlNGrUiHr16tG3b1/i4+MBqFy5MlFRUQCEhobSoUMHIPXIvW/fvnTo0IGqVasyYcKEi22+8sor1KhRg1tvvZVdu3b9I9Pq1auZO3cuw4YNo2HDhuzdu/cfeR5++GG+/fbbi99ToEABAEaMGMHKlStp2LAh77zzDgBHjhyhU6dOVKtWjeHDh7v+h2iMcTuP65b5N+sHw+lNrt1mkYbQ5N0MF4eGhjJ79mw2btxIUlISjRs3pkmTJheXnzlzhl9//ZW4uDiqVavGkiVLqF69Og899BBTp05l8ODBV2w+LCyMZcuWERMTQ40aNejfvz9btmzhq6++yrBNgFatWtG1a1e6dOlCz549/5EH4OGHH063zXHjxjF+/HjmzZsHpJ7S2bRpExs3biRv3rzUqFGDgQMHUqFChXS/3xjjGewIP4tWrVpFt27dyJcvHwULFuSuu+762/L7778fgF27dlGlShWqV68OQJ8+fVixYkWm2+/cuTN58+alePHilCxZkuPHj7Ny5Uq6d+9O/vz5KVSoEF27dr3qvH/lyapbbrmFwoULExQURO3atTlwIMPxmIwxHsKzj/CvcCSeU1JvGs5YcHBwpusFBASQkpIC8I++7Hnz5r343N/f/+K592vtBvlXnsvbVVUSEhIy/L6MchhjPJcd4WdRmzZt+PHHH4mLiyM2Npb58+enu17NmjWJiIggPDwcgM8//5z27dsDqefw169fD8Ds2bMzbbNdu3bMmTOHCxcuEBMTw48//pjuegULFiQmJibD7Vza7g8//EBiYuJVfZ8xxjtYwc+iG2+8ka5du9KgQQN69OhB06ZNKVy48D/WCwoK4tNPP+Xee++lXr16+Pn50a9fPwBGjRrFoEGDaNu2Lf7+/pm22bhxY+6//34aNmzIPffcQ9u2bdNdr1evXrz55ps0atSIvXv3/mP5448/zq+//kqzZs34448/Lh79169fn4CAABo0aHDxoq0xxvtIZqconJTeBCg7d+6kVq1aDiVKFRsbS4ECBTh//jzt2rVj2rRpNG7se/Oy54bfhTHm70Rkvao2TW+ZZ5/Dd0hISAg7duwgLi6OPn36+GSxN8Z4Hiv418BuUjLGeCI7h2+MMT7CCr4xxvgIK/jGGOMjXFLwReQTETkhItsyWN5BRM6KyKa0x4uuaNcYY8zVc9UR/nSgUybrrFTVhmmPMS5q16MtX76cLl26ADB37lzGjRuX4bpnzpxhypQpF18fOXLkb2PmGGNMZlxS8FV1BXDKFdvyBsnJyVn+nq5duzJixIgMl19e8MuWLfu3kS+NMSYz7jyH31JENovITyJSx43tulRERAQ1a9akT58+1K9fn549e3L+/HkqV67MmDFjaNOmDd988w2LFi2iZcuWNG7cmHvvvZfY2FgAfv75Z2rWrEmbNm347rvvLm730klHjh8/Tvfu3WnQoAENGjRg9erVjBgxgr1799KwYUOGDRtGREQEdevWBVLH43nkkUeoV68ejRo1YtmyZRe32aNHDxvm2BgDuK8f/gagkqrGisidwPdAtfRWFJEQIASgYsWKV9zo4MGwaZMrY0LDhvDuu1deZ9euXXz88ce0bt2avn37XjzyDgoKYtWqVURFRdGjRw9++eUXgoODef3113n77bcZPnw4jz/+OEuXLuWGG27IcCTLp59+mvbt2zNnzhySk5OJjY1l3LhxbNu2jU1pOxwREXFx/cmTJwOwdetWwsLCuO2229i9ezeADXNsjLnILUf4qnpOVWPTni8AAkWkeAbrTlPVpqratESJEu6Il2UVKlSgdevWADzwwAOsWrUK+P+hiNesWcOOHTto3bo1DRs2ZMaMGRw4cICwsDCqVKlCtWrVEBEeeOCBdLe/dOlS+vfvD6SOVJneWD2XWrVqFQ8++CCQOmhbpUqVLhZ8G+bYGPMXtxzhi0hp4Liqqog0I/UPTXR2t5vZkXhOuXyo4r9eXzo0cseOHZk1a9bf1tu0adM1D3N8JVcaD8mGOTbG/MVV3TJnAb8DNUQkUkQeFZF+ItIvbZWewDYR2QxMAHppbh61LRMHDx7k999/B2DWrFm0adPmb8tbtGjBb7/9dnFo5PPnz7N7925q1qzJ/v37L45kefkfhL/ccsstTJ06FUi9AHzu3LkrDmHcrl07Zs6cCcDu3bs5ePAgNWrUyP6OGmO8iqt66fRW1TKqGqiq5VX1Y1V9X1XfT1s+SVXrqGoDVW2hqqtd0a5TatWqxYwZM6hfvz6nTp26ePrlLyVKlGD69On07t2b+vXr06JFC8LCwggKCmLatGl07tyZNm3aUKlSpXS3/95777Fs2TLq1atHkyZN2L59O8WKFaN169bUrVuXYcOG/W39J598kuTkZOrVq8f999/P9OnT/3Zkb4wxYMMjZ1lERARdunRh27Z07zHzKU7/Lowx/3Sl4ZFtaAVjjPERVvCzqHLlynZ0b4zxSB5Z8HPzaShfYb8DYzyPxxX8oKAgoqOjreA4SFWJjo4mKCjI6SjGmCzwuBmvypcvT2RkJCdPnnQ6ik8LCgqifPnyTscwxmSBxxX8wMBAqlSp4nQMY4zxOB53SscYY8y1sYJvjDE+wgq+Mcb4CCv4xhjjI6zgG2OMj7CCb4wxPsIKvjHG+Agr+MYY4yOs4BtjjI+wgm+MMT7CCr4xxvgIK/jGGOMjXDWJ+ScickJE0p0ZRFJNEJFwEdkiIo1d0a4xxpir56rRMqcDk4DPMlh+B1At7dEcmJr21eQCSUmwfz/ExcFf0wxUqABFijibyxh3UoULF8DPDwICwN8fRJxO5VouKfiqukJEKl9hlW7AZ5o6a8kaEblORMqo6lFXtG+yJiEBFv6UxHdfHmfTFn927i1KfGKef6xXumg0daqeoEO7eO55qCq1GhRyIK0xOePcWeXHWftZsjCGsPB8hEWU4nRs4YvL8wTEU7tSBA1qRNOoYRJd/3U9VeqUczBx9omrZo5KK/jzVLVuOsvmAeNUdVXa6yXAf1Q1NJ11Q4AQgIoVKzY5cOCAS/IZ2LcPxr96iv99m5dTZ4MpWiCaZlXXUu+GI9SumUTBwoHgF0iKBhBxwI8duwuwJbwcG/Y3BKB2pQM8+uBpnvhPfYIL2OUf43lU4efvT/L+hGh+XlWVhKQ8FC94krqVwqlZ9QyVKqag+JGU7M+5GD+2hhVic3gljp0pBUCLWtv41z1n6DOkEYWKBju8N+kTkfWq2jTdharqkgdQGdiWwbL5QJtLXi8BmmS2zSZNmqjJvmPHVJ8KOa2BAQkaFHhee7f6UueNe1kT9s1VTTh75W9OSdbILaE6cfgcbV1rrYJqsUKn9JVnN+vZ00nu2QFjsiklRXXxvFPasv4+BdWyRSJ1cI9v9Lev52ry+ehMv3nf5n362qAlWr/yTgXVogWi9dVnVmvMmXj37EAWAKGaUZ3OaEFWH5kU/A+A3pe83gWUyWybVvCzJyVFdcqE8xqcL079/RL1iVs/0sOLx6teOH5tG0xO0tWzF+mdTZcrqJYuclJnz9jv0szGuNqRyETt3G6Pgmr5ogf1gxEzNP5UxLVtLCVF1/68QTs3/01BtXihKP3ozU2akuLazNmRGwp+Z+AnQIAWwNqr2aYV/Gt38qRq19ujFFQ71lukYV+/qHr+qGs2npKsf8z5WRtW2aKgevfNOzTyQO470jHm288Oa7FCpzUo8LyOf/JTvXB8t2s2nJKia378XdvVXaegelvzbXogPMY1286mHC/4wCzgKJAIRAKPAv2AfmnLBZgM7AW2Ak2vZrtW8K/NbysTtUyJs5onIE7f7jtWk4//niPtJMRE6ev9v9SgwPNavNApXTL/RI60Y0xWxcerPnZf6umXptev152/zMuRdpIT4nTyc3M0OG+MFgiK0Znvh+dIO1nhliP8nHhYwc+6Od+c16A8cXpDqd26cfoLmZ+jd4GwZQu1dvkd6ueXpONHR+Sqj7fG95yOTtJbmoUpqD7X+0tNOHM4x9vct3attkm7xjW8X5gmOXh5ywq+j5jy7mn180vS5jes0ZN/THdr2+cO7tCereYrqP672z6NtzM8xgERe2K0TuUIDfBP0OkvzVRNdl/ljT97Qvt3+U5BtVObcD19ypkjHyv4PuDVF48rqHZpvED/DP/ZkQwpF6L0lb4fKqje2T5Cz593JIbxUft2ntbyxY9q4fyndcmMH5wJkXRB3x/2sQb4J2jD6gf1xPFkt0ewgu/l3n3tWOqRdbtvNfH4BmfDJMXpB0MnqUiytmsaqWdz/oySMXpwzymtXCpSiwRH68aFK5wNk5KiC6d8pPny/Km1Kh/Rw5HuLfpXKvh294yH+2TycQY/V4ruzecz/bs6BJRs5Gwg/7yEvP44M194j9UbS3Jrm6OcO+dsJOPdjkac4ub2MZw6V4BF34TR8La2zgYS4bZ+fflp8kwOHStAuxZRHIhIcTZTGiv4Hmz2zOM8NrAEtzdcyqwfqhBQrKbTkVL556H3qKeY/fK7bNhegrtvP0JcnNOhjDc6GxVDxw6nOBpdlJ+/2knTO1o5HSmVCO0ffYzFH3xB9KlAbm0XxYnjrhnVIDus4Huo0NVneKBvYVpWX8d384qTt1RtpyP9nV8gXYcPZsaIt1i2piy97z5GUpLToYw3SUpI5L47drMrshI/zNhOy64tnI70dyK0eLAfCyZ/weHjBbjj5uPExDgbyQq+Bzp8MJ5uXRMpVegYc2ZD/nL1nY6UPr9A/v3SAN7rN57vF5am38MnUOcPcowX0BRlUO+VLAptwvtj13DL/bl08F0RWvYZwDdjJ7A5rDjd7zhGfLyDeTI6uZ8bHnbR9p/+jE3RpjX3anDeGN28YIHTca7OheP6wn0TFFTffDmTcUuMuQoTRvykoDrs4ZVOR7k6SRd0+rOvpHauuOdYjt6rgvXS8Q4pKaoPdNmsIsn6w8SvnY6TJSlndut9LWerSLLOn3vB6TjGg/36zQr190vUbm1DNTnJg+7yi4vWsQ+8k3rg88rpHGvmSgXfTul4kI/f2sYX8+rzUt85dB3Q0+k4WSKFq/HJZwVoWGkTvXunELbTzu2YrDseHk6vkBuoWuYIn/1QBz9/D5qhJG9Rnp90B/e2+I7/vFCQhQsS3B7BCr6H2LLmMANHXk/HRr/z/OQ7PHIqnuAbbuP7D1cT5B9D1ztOc/as04mMJ0mOi6H3PVGc+bMws2fnoVCRIKcjZZkUrsGn0wOpW34bvXolEh7u3vat4HuAmDNx3NsziSIFzvDFt2Xwz5vf6UjXrOItA5j96iT2HSpEyEMn7SKuuTqqjApZxLItLZjyxgHqNS/tdKJrFlzjLr6f+gv+eoEeXU5x4YL72raC7wGe7L2Z8CPlmfXBPkpWrex0nOwRoU3IcF7+9zt8PbcE0yb/6XQi4wGWfjaXV7/oTt8eW3h4UC2n42RblU6D+eL5d9i6qyhDn4p2X8MZndzPDQ+7aKv61aTUEfheemKh01FcKvlkqN5e/2fNmydeN230oAtvxu1O7d+u5Yse0urlD2lsjPvHpskx54/psG6TFFS//V+cyzaLXbT1TIfDj9F/xA00r7GV59/r4HQcl/Ir3oTPpuynaP4o7ut+hthYpxOZ3EgTL9D/oQMcO1uKmbPyeddcyvlK8fK71Wh2/R88+mgyERE536QX/fS8S0pyCo/0Okx8Yh4+nxVMQN48TkdyuZKtnmDmixPZc6AwwwedcjqOyYW+HPc//rfyDl4aGkHTNsWcjuNyeSrfxqy3f0GTE/lXz1MkJ+dse1bwc6kpo5azeH0T3n5+A9UaVXU6Ts4Q4ab+zzCkywdM/aQoC3+ysRfM/zu0bjlPvtad1g32M+LVak7HyTFVOz/L1Kde5/f1RRn/Ws5+1BXNxd0kmjZtqqGhoU7HcLu9m8Kp17wsHRrtZP7qxoif53XBzIq4Pd/TuEN1ziaVZ1tYIYoUcTqRcZrGn+HOlhtZsaM5W7f6U7VaXqcj5Sg9s4N7bw/jx413sX59AHXrXfv/eRFZr6pN01vmkiN8EekkIrtEJFxERqSzvIOInBWRTWmPF13RrjdKSUrisT5nCQxI4sMvKnp9sQcIqnY3n435iuNR+RkY4sYeCybXmj52Nj9vvInXR5/0+mIPINfVZupbhymc7zQP9T5NYmIONZTR1dyrfQD+pE5OXhXIA2wGal+2TgdgXla37Yu9dKa8sFBB9aNxfzgdxb3iT+mo+8YrqM6ZbfMj+rLIdYu1cP7T2q7JPk32ok45mUpO0u9eGK6gOmpkzDVvhhzupdMMCFfVfaqaAHwFdHPBdn3Oga17GP5mSzo23UTfYTc6Hce98hTh+TfqUq/CFp7sF2d34foojT/NE/2UhOS8fDyzHH6+dJXRz5/uQx/hgTZfMu2DBP6Mdf3pdlf8OMsBhy55HZn23uVaishmEflJROpktDERCRGRUBEJPXnypAvieQZNTibk4WhA+PCLcj5xKudygZVu5+NR33E8KpgRQ+zUji/66o1vmb++I6++GMUNNbyvZ1qmCtdk4vhTbPqgH8FB512//YwO/a/2AdwLfHTJ6weBiZetUwgokPb8TmDP1Wzbl07pzHh9sYLqpJfWOB3FWRdO6jN3TVZQXbE8yek0xo2id67SEoWOa/O6EZrky7/6lGTNzvjJ5PApnUigwiWvywNHLvujck5VY9OeLwACRaS4C9r2CicijjJkbGNa1dlO//82czqOs4KKM2ZcMSqX2M9jD5+zqRF9RXIcwwYe5fSfRZg2oyT+/k4HcpD45djgiK4o+OuAaiJSRUTyAL2AuZeuICKlRVL3QESapbVrn9nTDHo0nNi4YD78tKBnDfeaQ4Jr3ce0YR+xO6IIr48943Qc4wbLPv2ST37pybP9I6nfOJ/TcbxWtgu+qiYBTwELgZ3A16q6XUT6iUi/tNV6AttEZDMwAeiV9tHD582bvoavlrbl+SfWUvvGik7HyR1E6PhkCL1bfc1r4/O7fQhZ415xx3bwxAttuL7ccV58o4rTcbya3XjloNjTsdSufpZCwRfYEFaJPEGBTkfKVY7+OpkanR6kVfM4flpW0hOnADCZUeWlPtMZ/fkjLJp3ho6dr3M6kcfL8RuvzLV5+ZlQDkWV44NJF6zYp6NM2xBefmgSC38tyXffODnzs8kpe5bNZdxXvendJdyKvRtYwXfIzrV7eevz1jzSeSWtu9RzOk7u5BfIk6Pa0LDSRgYNjLMRNb2Mxp9h4NCC5AlM5q0PvHS8qFzGCr4DNEV5qt9ZCgT9ybgpnj+ZQ04KKNuOKSN/5PCJwoz9r13n9yaz353Nwk038/J/T1GmrJUid7CfsgO+nvI7Szc25tVhWyhZ0XqnZqblQ/14uMNM3plciD27c+81J3P1Yg5sYvAbt9Ow+iGeHFYh828wLmEF381iT8fyzKgqNKm2g5CRrZ2O4xmCSvLa2AsEBVxgSP/jTqcx2aXK2GHbOXyqPFM/uo6AAKcD+Q4r+G72ytBQjpwqw6QJKfgH+vLdJVlTutXDjPrXB8xfWpr5c+1uLE8WtuRH3vnuPvr23E2LtgWdjuNTrFumG+3ZGEHdZmXofds6ps9v43Qcj5NwaAX1m5ckJbAEW3cXI6/3j5rrdTQhhttu3Mi6vY3YvTeYkqXsmNPVrFtmLvHMgBPkCUjgtYneO3tPTspToR3vDp3DnoPFeO8NmxLRE82Z+D2/bGnH2Oejrdg7wH7ibvLTF+uY93szXhywnjJVSzkdx2N16v8gXRov4OVxQRy30/ke5fyxcIaMa0f9Gw7Sf1hlp+P4JCv4bpBwIYHBI4pTrex+Bo1t5XQcz5a/PONHRXAhPpAXnj2S+fom1xg3PJSDUZWYOCXYLtQ6xAq+G0x6aTW7D1fhndeiyJPPB8f4drEadz7CU3fO4KOZpdm0IdnpOOYqRKxdwZtfdaPXHTtp17GY03F8lhX8HHbyUBRjJjXi9htDufOBdK+jmKwKyMeLLxejaPAphjx5nFzc78AApCTx7JA4/PyUN6bYHbVOsoKfw0YN2UFsXDBvT7zOJ2exyilF6t3NmIc/Y/kfZfn+2z+djmOuYNnnPzJ79W08NzCCCpWta5WTrFtmDtr6224atr2eAfetYsJX7Z2O43WSTmygQeO8xEspduwtTh47W5brJP15ika1jhGbWIQde0uTL78d9OQ065bpAE1RhgyMpXD+c7z0Tn2n43ilgJKNeWvoIvZGFmfyW74z/7EnmTZmCdsO1eat1+Ot2OcCVvBzyLwZ61iysTGjB2+haJkiTsfxWp369eL2BosZ82o+om1stVzlVMRuXphyMzc1CaP7g5WdjmOwgp8jEi4k8OwLJahZfi/9XrBumDkqXxnGvxTBuT/zMWbEIafTmEuMHhrGmT+v492pJWzymlzCCn4OmDLmd3YfrsL4V04RmNcmNslpdbs8wOO3fcWUT0uza6d108wNdq5YzeTv7+Txe7dS/0brhplbuKTgi0gnEdklIuEiMiKd5SIiE9KWbxGRxq5oNzeKPnKK0RMb0LHJeuuG6S4B+Rj9cjD5Ai8w7KlIp9OYlCSeeSaF4KALjH3P5nvITbJd8EXEH5gM3AHUBnqLSO3LVrsDqJb2CAGmZrfd3Gr0M1s5d74gb08oZN0w3ahUk26M/NdMflxaiaWLzjsdx6f99Mkifl7fhheH7KNEaeuGmZu44gi/GRCuqvtUNQH4Cuh22TrdgM801RrgOhEp44K2c5WwdfuY8k1rHr/7N+q2sgHS3EqEwaObUql4BEOfPkOyndlxROKfZ3nmpRu4oewhBr5gvdNyG1cU/HLApVfLItPey+o6AIhIiIiEikjoyZOe1dXu2aejyJ/3PGPetY+xTggqfyOvD/yRTbvK8tmHUU7H8Unvj1lO2OHqvPV6HHny2ifc3MYVBT+93+rld3NdzTqpb6pOU9Wmqtq0RIkS2Q7nLou/Ws/8Nc34b/8NlKzoObm9zX3P3E2Lan/w/H/9bdJzNzt1MIJRk9tyS9Pt3PVv+4SbG7mi4EcCl05KWR64fBjDq1nHYyUlJPHMiEJULX2AQWNbOh3Hp0mBCrzz4maORhfhjVF2AdedRg/dwdnzhXl7UnHrhplLuaLgrwOqiUgVEckD9ALmXrbOXOChtN46LYCzqnrUBW3nCp+8sZptB6rxxqgj5M1vF6mc1uL+f9GrzfeMn1ycyEO5d+gQbxL223omf3cbj/fcSP3mNt9DbpXtgq+qScBTwEJgJ/C1qm4XkX4i0i9ttQXAPiAc+BB4Mrvt5hbnos/xwvhatKu3iR4hLZyOYwACCzDu1UQ0RXnu6Qin03g/TeHZZ84THGTXr3I7l0xDoKoLSC3ql773/iXPFRjgirZym1eGbuDkuXYseDfKumHmIpXa3MMzPT7l1f89ysDVcTRrFeR0JK+1cMZS5q+9lTefW0/Jsk2cjmOuwEbLzIa9mw9Qu2lp/n37Wj6Z19bpOOYyMftWU71JFapWTmLVhgp2XjkHJF2IpUGNw8Qn5Wf7vnLkDbKb951mo2XmkGEDjxLon8grE6o7HcWko2DVVrwc8j2rN1Xg689t0vOc8MHY5ew4VIPx485bsfcA9hu6Rstmb2TOyhaMfCLUJiXPxR4e2YmGlTYxfHgK5+0GXJc6HXmIFye25KbG2+n2YA2n45irYAX/GiQnJjNkWH4qlYhkyMvNnY5jrsC/cBXe/e9aDh4vzvgx1k3TlcYM3Zo6GuaUYna6zENYwb8GH7/+G5v31+CNUQfJVzCf03FMJtr36c29reYy7t3iHDqY4nQcr7BzVSiTZnfksR4bqd+8tNNxzFWygp9Fp4+fYeQbdWhbdzP39rebrDxCYEHeeC21m+Z/njrgdBqPp8nJDBmcQHDe87w88fJxEk1uZgU/i14atJnTsdcxYXKQdcP0IJXbdmfYvV8y68cqrFpuJ/OzY8Eni1m4vhWjntlHiTL5nY5jssC6ZWbB9t/DadCmMo/fvZqps9s5Hcdk0Z8H1lKzcRlKlPRj3bZy+Ps7ncjzJMSeoW71aPwCAtiyp6INkJYLWbdMF9AUZdCAcxTMF8vY9+o4Hcdcg+BKzXhz0Fw2hpXjwwknnI7jkSa+8Ct7jl7P2+OTrNh7ICv4V2nOR3+wZGNjxgzeTPHyNmWbp7r/2R7cVOdXRo7KR9TJ3PvpNjc6tiuM0R/cxB0tt3Hnfdc7HcdcAyv4V+HPs38y5L/lqVtpD/1fbO10HJMNkr8ME1+NIOZ8ECMHH3Q6judQ5T8DI4hPzMt7H6Y7lYXxAFbwr8KrQ9dx8GR5pkw4T0Aelww/ZBxUp8u/ePqumXw0qwLrfo9zOo5HWP3dL3y2uBNDH91BtTpFnI5jrpFdtM3E7g37qde8LPffuo7PfmrjaBbjOuf2/EqNZtUpXy6FNZvtAu6VJMed48baBzhxriRh+4pToJD9sHIzu2h7jTRFGfhENEGBcbwxxcbL8SaFqrXnrae/IXR7Od5/17Om0nS3D8csZuP+erz12jkr9h7OCv4VfDdtDYtCmzJ2yCZKVynpdBzjYr2H38Ot9ZYyclR+jhzOvZ90nXRyz3ZGTriJDo3DuO8xm7bQ01nBz8C56HMMer4yDars4slRdqHWG0lwOaaOP0R8gj9D+tk4O/+gKQx7MoLY+AJM+aS0jZfjBazgZ+C/AzZy5HQppr2fZBdqvdgNt/6b5+//lK/nVeDneX86HSdXWT5zHjN+6cywx8Oo1eA6p+MYF7CLtulYu2g7LTrVYsC9K5n4v/Zub9+4V/yRUBo0LUCCFGfr7uIEBzudyHkJZ4/RoM5Z4pMLsi28DPmD7fDeU+TYRVsRKSoii0VkT9rXdPtriUiEiGwVkU0iknvGSkhHUkISIf0CKFPkOK9MaeR0HOMGecs2Zdqon9h/pDgvPHvU6Ti5wvjhvxJ2uAaTJqZYsfci2T2lMwJYoqrVgCVprzNyk6o2zOgvT27xzshVbN5fg4mvHaBQsUJOxzFu0q7vo/Tv9BnvflCK31clOB3HUbtXLmPsp12559Yd3NmzvNNxjAtlt+B3A2akPZ8B3J3N7Tlq1/p9vDihOd3a/EH3x2xiE58SWIhx75SmfNFIHu1zhvh4pwM5IyXuDI8+kZ+gPIlM/PQGp+MYF8tuwS+lqkcB0r5m1HdRgUUisl5EQq60QREJEZFQEQk9edJ9/aOTE5Pp+1As+fLEMXVGZRv62AcVqnkb00Z+xc59JRn7/HGn4zhi6gvzWbWzOe+Mi6JM+TxOxzGupqpXfAC/ANvSeXQDzly27ukMtlE27WtJYDPQLrN2VZUmTZqou7wzYrmC6mdvrXRbmyYXunBS+3SYpf5+ibp2TaLTadxq/9qVGpw3Rm9vGaYpKU6nMdcKCNUMamqm/Q1V9daMlonIcREpo6pHRaQMkO6Ys6p6JO3rCRGZAzQDVlzVXyQ3CN90gJFv30jnFmt5YLD1ufdpQcV55728LLnpKA/2yseG7cXJ7wNzfGjCOZ4ISUH8hA8+r2R97r1Udk/pzAX6pD3vA/xw+QoiEiwiBf96DtxG6ieEXCEpIYmHHzhLnoBEPvi8gp3KMRSp353pL37GrojijBjsG+PmTxn5A4s2teP1UcepdH2Q03FMDsluwR8HdBSRPUDHtNeISFkRWZC2TilglYhsBtYC81X152y26zLjhq7it+31mfzyNsrdUMbpOCaXuKX/kwzq/BETPyzJop+8+wruzqWLeXZCTzq13k3/4VWdjmNykE/fePXHwm20vrMm9938B18utlM55u8u7FtCk7ZlOJtYls07rqN4cacTuV7C2aO0bHyCA1GV2LojmDLlAp2OZLLJRstMR+zpWB54pADlih1jysy6TscxuVC+qrcw840fiTqdj4d7nSAlxelELqYpjB7wKxv2NeDDKX9asfcBPlvwn35wI3uPVeTzD6O5rmRhp+OYXKrR/U/z9uPjmb+kJG+PO+t0HJf65ZNveO3L++h7z066/9tmsfIFPlnwP35tJZ/Ob8t/H19Bu24NnI5jcrOAfDz5Wk96Np/DiBeC+f23JKcTuUTkpj/oPeRmaleOZML0mk7HMW7icwV/4/IwBoy6kVsbr2fUpLZOxzEeQArX4KMPEqlU/AD394wlKsrpRNmTGHOC+3v5cSExP9/+UJTgAtYzzVf4VME/c+IsPXvno3jB03z5fSX8A232HnN1Cje4j6/f+JIT0UHc1y2KxESnE12jlGRG9F3B6l038vGkKGrWK+B0IuNGPlPwkxOTefDuXRw8WZZvPo+iRAUv7HJhclSTfz/Lh4NeZdnq4jwzINrpONfk81f+x9vf9uSpB7dz/6OVnI5j3MxnCv7wR1Yy7/dmvPf8alreWc/pOMYTBeTjwdEhDO06lUkfFuPDKbFOJ8qSFV/O49HRPbmp6W7e+qiO03GMA3yi4L8/ZgVvz+zA0/f/ypOjbUITkw35y/P6tEZ0arCQAYPysmyJZ1zEDV/zB92faEnVsseZ/XNV8ti4aD7J6wv+wi9DeWp0Kzq3WMvbn7dxOo7xAv6lWjBrxmmql95Ft66JbNyQuzvoR+3bQ+cexRDxY/7C6yhSzKbs9FVeXfDX/LyNno/WoG6lvcyaX8su0hqXua5BLxbOWEqRfCe4o2Mse8Nz5x3rpw8doOOt8RyMLsf3357n+loFnY5kHOS1BX/Dsp10uqcCpYtEs2BxYQoWtX/oxrXK3TSQhR98RVJCArfddJojR5xO9Hfnjh2l0y2n2XGoGnNmHqPNbXZzla/zyoK/9bfddOxaiuuCY1iyNJCy15d2OpLxRiLU7DGc+e9O5fjJPLRveYqDB50OlSo26iSdbznChn11+PqTA3TqWcXpSCYX8LqCH33kFLd2LkK+PPEsXZJCxZp2VGNykAjNH3mOxRPGc+KkP+1anHL89M7xfQfo0OIYv4c1YOaU3XR7sLqjeUzu4XUFv1jZorw4aAdLFl2gar2KTscxvsAvgJaPv8jS96cSE6O0a3WGbVuSHYmye10YLVvCzsiq/PD5Hu4Lse6X5v95XcEHGDC6PTWa2Ljexo3EjyYP/ofln84kJTGOli3i+f6bGLdGWP7tWlrdUoLYuGCWLzhG53/Vcmv7JvfzyoJvjCNEqNfzadbNXULNMjvofl9Bxjx3NMeHVU5OTGZ0/6Xccl8Tihc+x+qVCdx48/U526jxSFbwjXGx8m0fYMXyFB7s8C2jxpXh9jYH2b83Z07xHAw7wq03buGl92/mgU5rCN1aihvql82Rtozns4JvTA7IV6EZMxa05/0hE/lj43XUrZPAhNcOkuyiun8hNp7RA1ZSo34R1oZVZ/obq5ixoDUFrvOBGdfNNctWwReRe0Vku4ikiEi6U2qlrddJRHaJSLiIjMhOm8Z4CslXgifeeortS3+lfZ3VDBpZkXo3HObz9w+SdI0jMpyPiefD19ZQ6/qTvDSlLd3armfnxlP0GWZ3kZvMZfcIfxvQA1iR0Qoi4g9MBu4AagO9RaR2Nts1xjOIUKHlXcxf3ZSvx80gIOU0D/WvSPWKR3lt+Ba2bThDZtNKJyUqocv38WyfVZQrc4GQkS0oVvAsy2ev46slbahYq4J79sV4PJdMYi4iy4FnVfUfM46LSEvgJVW9Pe31cwCq+lpm283pScyNcbeUuNPM/3gJr0+qyG9hzQCoWPIoLRscoUK5RCpUEIKC4FR0EtHRsHN3ECs3V+Pc+UIE+CfSs/3vPPV0EK3uaor42RlZ809XmsTcHaMolQMOXfI6Emie0coiEgKEAFSsaP3ojXfxCyrCXQN6clf/ZI7sWM+Cbw8zb9F1hG4pz/fLyxKfGHRx3aDAC1QuGUnvjqF0uEm4uWs1SlZp52B64+kyLfgi8guQ3tgEz6vqD1fRRnrzp2X4sUJVpwHTIPUI/yq2b4zn8fOnbN0mPFa3CY+9lPqWJp4nKnIf8RdSKFamMPkKFwG/akA1J5MaL5JpwVfVW7PZRiRw6UnG8kAuG2bKGOdJYH5KVLEbBk3OccdJwHVANRGpIiJ5gF7AXDe0a4wx5hLZ7ZbZXUQigZbAfBFZmPZ+WRFZAKCqScBTwEJgJ/C1qm7PXmxjjDFZla2Ltqo6B5iTzvtHgDsveb0AWJCdtowxxmSP9esyxhgfYQXfGGN8hBV8Y4zxEVbwjTHGR1jBN8YYH2EF3xhjfIQVfGOM8RFW8I0xxkdYwTfGGB9hBd8YY3yEFXxjjPERVvCNMcZHWME3xhgfYQXfGGN8hBV8Y4zxEVbwjTHGR1jBN8YYH2EF3xhjfER257S9V0S2i0iKiDS9wnoRIrJVRDaJSGh22jTGGHNtsjWnLbAN6AF8cBXr3qSqUdlszxhjzDXK7iTmOwFExDVpjDHG5Bh3ncNXYJGIrBeREDe1aYwx5hKZHuGLyC9A6XQWPa+qP1xlO61V9YiIlAQWi0iYqq7IoL0QIASgYsWKV7l5Y4wxmcm04KvqrdltRFWPpH09ISJzgGZAugVfVacB0wCaNm2q2W3bGGNMqhw/pSMiwSJS8K/nwG2kXuw1xhjjRtntltldRCKBlsB8EVmY9n5ZEVmQtlopYJWIbAbWAvNV9efstGuMMSbrsttLZw4wJ533jwB3pj3fBzTITjvGGGOyz+60NcYYH2EF3xhjfIQVfGOM8RFW8I0xxkdYwTfGGB9hBd8YY3yEFXxjjPERVvCNMcZHWME3xhgfYQXfGGN8hBV8Y4zxEVbwjTHGR1jBN8YYH2EF3xhjfIQVfGOM8RFW8I0xxkdYwTfGGB9hBd8YY3yEFXxjjPER2Z3E/E0RCRORLSIyR0Suy2C9TiKyS0TCRWREdto0xhhzbbJ7hL8YqKuq9YHdwHOXryAi/sBk4A6gNtBbRGpns11jjDFZlK2Cr6qLVDUp7eUaoHw6qzUDwlV1n6omAF8B3bLTrjHGmKwLcOG2+gL/S+f9csChS15HAs0z2oiIhAAhaS9jRWTXNeYpDkRd4/d6Kl/cZ/DN/fbFfQbf3O+s7nOljBZkWvBF5BegdDqLnlfVH9LWeR5IAmamt4l03tOM2lPVacC0zHJlRkRCVbVpdrfjSXxxn8E399sX9xl8c79duc+ZFnxVvTWTMH2ALsAtqppeIY8EKlzyujxwJCshjTHGZF92e+l0Av4DdFXV8xmstg6oJiJVRCQP0AuYm512jTHGZF12e+lMAgoCi0Vkk4i8DyAiZUVkAUDaRd2ngIXATuBrVd2ezXavRrZPC3kgX9xn8M399sV9Bt/cb5fts6R/FsYYY4y3sTttjTHGR1jBN8YYH+EVBV9EPhGREyKy7ZL3iorIYhHZk/a1iJMZXS2Dfb6qoS48WXr7fcmyZ0VERaS4E9lySkb7LCID04Ys2S4ibziVLydk8O+7oYisSbteGCoizZzMmBNEpIKILBORnWm/10Fp77uknnlFwQemA50ue28EsERVqwFL0l57k+n8c58zHerCC0znn/uNiFQAOgIH3R3IDaZz2T6LyE2k3rFeX1XrAOMdyJWTpvPP3/MbwGhVbQi8mPba2yQBQ1W1FtACGJA2FI1L6plXFHxVXQGcuuztbsCMtOczgLvdmSmnpbfPVznUhUfL4HcN8A4wnCvc1OepMtjn/sA4VY1PW+eE24PloAz2WYFCac8L44X386jqUVXdkPY8htSejeVwUT3zioKfgVKqehRSf4hASYfzuFtf4CenQ7iDiHQFDqvqZqezuFF1oK2I/CEiv4rIjU4HcoPBwJsicojUTzTe+An2IhGpDDQC/sBF9cybC77PymSoC68iIvmB50n9iO9LAoAipH7sHwZ8LSLpDWPiTfoDQ1S1AjAE+NjhPDlGRAoAs4HBqnrOVdv15oJ/XETKAKR99aqPvBm5ZKiLf2cw1IW3uR6oAmwWkQhST2NtEJH0xn/yJpHAd5pqLZBC6iBb3qwP8F3a829IHYnX64hIIKnFfqaq/rW/Lqln3lzw55L6D4S0rz84mMUtrnKoC6+iqltVtaSqVlbVyqQWwsaqeszhaDnte+BmABGpDuTB+0eRPAK0T3t+M7DHwSw5Iu1T2sfATlV9+5JFrqlnqurxD2AWcBRIJPU//KNAMVKvZu9J+1rU6Zxu2OdwUoei3pT2eN/pnO7Y78uWRwDFnc7pht91HuALYBuwAbjZ6Zxu2Oc2wHpgM6nntZs4nTMH9rsNqRent1zy//hOV9UzG1rBGGN8hDef0jHGGHMJK/jGGOMjrOAbY4yPsIJvjDE+wgq+Mcb4CCv4xhjjI6zgG2OMj/g/Udoubcv9mqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM, SimpleRNN\n",
    "\n",
    "def split_sequence(sequence, step):\n",
    "    x, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        end_idx = i + step\n",
    "        if end_idx > len(sequence) - 1:\n",
    "            break\n",
    "            \n",
    "        seq_x, seq_y = sequence[i:end_idx], sequence[end_idx]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x = np.arange(start=-10, stop=10, step=0.1)\n",
    "train_y = [np.sin(i) for i in x]\n",
    "\n",
    "n_timesteps = 15\n",
    "n_features = 1\n",
    "\n",
    "train_x, train_y = split_sequence(train_y, step=n_timesteps)\n",
    "print(\"shape  x:{} / y:{}\".format(train_x.shape, train_y.shape))\n",
    "print(train_x)\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features)\n",
    "print(\"train_x.shape = {}\".format(train_x.shape))\n",
    "print(\"train_y.shape = {}\".format(train_y.shape))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=10, return_sequences=False, input_shape=(n_timesteps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, mode='auto')\n",
    "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping])\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "test_x = np.arange(10, 20, 0.1)\n",
    "calc_y = np.cos(test_x)\n",
    "\n",
    "test_y = calc_y[:n_timesteps]\n",
    "for i in range(len(test_x) - n_timesteps):\n",
    "    net_input = test_y[i : i + n_timesteps]\n",
    "    net_input = net_input.reshape((1, n_timesteps, n_features))\n",
    "    predict_y = model.predict(net_input)\n",
    "    test_y = np.append(test_y, predict_y)\n",
    "\n",
    "plt.plot(test_x, calc_y, label=\"ground truth\", color=\"orange\")\n",
    "plt.plot(test_x, test_y, label=\"prediction\", color=\"blue\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 3s - loss: 0.6755 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6711 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.7036 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.6546 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6528 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6586 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6752 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6557 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6756 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6752 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6714 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6824 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6369 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6990 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.6711 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6442 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6830 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6351 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6745 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6460 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6318 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6621 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6633 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6972 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.6695 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6318 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6936 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6391 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6669 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.7059 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.6074 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6558 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6702 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6883 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.6171 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5922 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6596 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6193 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6439 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6094 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5813 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6061 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6353 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.7498 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.6884 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6122 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6228 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6626 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6120 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5832 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5715 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5662 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6095 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5787 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5443 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5647 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5799 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5775 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6508 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5406 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6192 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.5830 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5381 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5438 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6021 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5415 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5380 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.7846 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.5307 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6854 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.4929 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6690 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.6717 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.5398 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5369 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5542 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5059 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4934 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6567 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.5416 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5904 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.5469 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5431 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5163 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5417 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4339 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6043 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4683 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5415 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5366 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4661 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6633 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.4769 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6290 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4053 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4474 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3844 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3884 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4571 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4062 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4098 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4317 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3859 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4080 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6505 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.4222 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4353 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4235 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5981 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5447 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4783 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4229 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4145 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3318 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3619 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3219 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3382 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3918 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3365 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3759 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3166 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3290 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3367 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3476 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4771 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2976 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2731 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.9568 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.3302 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3059 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3073 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2972 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2558 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2384 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2810 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2631 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2640 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2748 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6551 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2482 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2669 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2879 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3181 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2428 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2600 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3324 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2346 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2458 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2535 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2775 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2981 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 1.0834 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2463 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2581 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2802 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2308 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 1.2160 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.5995 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2414 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2357 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5045 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2309 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2968 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2944 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3847 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2444 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3360 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2385 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1763 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2386 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4669 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2601 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2472 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2117 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1998 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1956 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3001 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3408 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2802 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2006 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4672 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3238 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1685 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1746 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2590 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1879 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2739 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1743 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2466 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1611 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3494 - accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.2168 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1763 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2135 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2439 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2840 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1606 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1775 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1614 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2264 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1910 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1660 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 1.6616 - accuracy: 0.2500\n",
      "1/1 - 0s - loss: 0.4718 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2596 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1927 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2314 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1687 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2449 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2448 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2024 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4825 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1432 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2726 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1898 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2559 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1508 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2132 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1940 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5682 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2447 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2679 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4885 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1938 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2479 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2033 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4988 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2305 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1514 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1469 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1608 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2924 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1836 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1782 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2709 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2527 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 1.2576 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1709 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2371 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1872 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4914 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1886 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2442 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2172 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1683 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1403 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3255 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2108 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1633 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2219 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1822 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2097 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1934 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1764 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4641 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1691 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2206 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1893 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2313 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2801 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2425 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 1.1929 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2450 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2015 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2084 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2271 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4142 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1682 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2135 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1445 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1845 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1207 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2897 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1403 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2027 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2820 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1631 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1769 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1432 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1171 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2110 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1288 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 1.4770 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.5341 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1843 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1805 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2188 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1562 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2139 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1423 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1970 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1538 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1853 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1652 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2084 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1970 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1977 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1717 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1507 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2476 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4509 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2562 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1472 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4462 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1666 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1569 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4894 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5013 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1383 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2576 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1661 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1271 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1448 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2260 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2814 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1231 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2709 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1742 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2148 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2315 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1870 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1313 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1617 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2294 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1973 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 1.2162 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2425 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1101 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.7031 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1540 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1597 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5035 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1409 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1779 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2080 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1837 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1754 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1192 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1126 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1420 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3041 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4674 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1775 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2976 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5194 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3275 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1929 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1586 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2163 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2249 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2382 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2775 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 1.2917 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1185 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2692 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4993 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1673 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1512 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1543 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1752 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1264 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1824 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1811 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2113 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1426 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1559 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2623 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1921 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5113 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 1.4146 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 1.3540 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1239 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1917 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1751 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1597 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1743 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4832 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4484 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1215 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1418 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1317 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1348 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.1298 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1941 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3141 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1286 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3452 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1753 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.8762 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1520 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2778 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1497 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1357 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2382 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2239 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1378 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1669 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1378 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2921 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1655 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1197 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3051 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1896 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1811 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1970 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1744 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1619 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1799 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1719 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2312 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2806 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1626 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1336 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2080 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1758 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1956 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1392 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1300 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6860 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2000 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2028 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2628 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1638 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1304 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1044 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1750 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4165 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1958 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4883 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1857 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1806 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2373 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6319 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2153 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2239 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1713 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4665 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1853 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4579 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2101 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1595 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6416 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1633 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1290 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1446 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1602 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2798 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1962 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1111 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1165 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2672 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1115 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1606 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3106 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2394 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1731 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1376 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1487 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1750 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2087 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2049 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2584 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1133 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1800 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1344 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1910 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2031 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1705 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1320 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1119 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 1.4372 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1037 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5350 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2217 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 1.3621 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2038 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1142 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2046 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1762 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1475 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1904 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1329 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5130 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4054 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1470 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1571 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2130 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1540 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2270 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1418 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5026 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1503 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1559 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2370 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1979 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1703 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4405 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2353 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1977 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1347 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5971 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1245 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1651 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2090 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2007 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1960 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4321 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2273 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.7436 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1958 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.9399 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2118 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1353 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2398 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1832 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1863 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1898 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1140 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1002 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2495 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4671 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1322 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1956 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1470 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2189 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1577 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1800 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1621 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1732 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1919 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1812 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1570 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0968 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1677 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.8988 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1144 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1987 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2785 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1293 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1615 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1295 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1297 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5986 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1736 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1392 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.8594 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2018 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1795 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1554 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1663 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1618 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2167 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5697 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2273 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1540 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1669 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0817 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5132 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1746 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1738 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2030 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1455 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4163 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1508 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1435 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1471 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2951 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1207 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1789 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2176 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1283 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2093 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0998 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.1992 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1394 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1596 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1022 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1181 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.8456 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1271 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1509 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1232 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0868 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2044 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 1.2104 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1689 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1351 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1379 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1969 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2224 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1566 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4571 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2441 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1460 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1917 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1318 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4791 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1064 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1341 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4345 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1646 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1573 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1596 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3757 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1908 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.9325 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2483 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2214 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3280 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1659 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1242 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2900 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1278 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2278 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1259 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1429 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2166 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1382 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2414 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1366 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1582 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1145 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1492 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4293 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1415 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2544 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1699 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3933 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1736 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2721 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1922 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1762 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1116 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1636 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1570 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1540 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2548 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1398 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1398 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4954 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1477 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1754 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2169 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.9807 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.0732 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1919 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2171 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.5965 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1383 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2442 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1051 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5998 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1262 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1509 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6936 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1676 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3586 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1516 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1598 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1241 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1669 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1547 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3073 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2060 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1635 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3520 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1377 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1986 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4356 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2130 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1606 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4717 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1616 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1560 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1302 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2406 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1334 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2439 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1684 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1310 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1483 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1482 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1492 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1818 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1184 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0956 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1950 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1658 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1856 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1527 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1544 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5937 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1524 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1649 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1451 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1363 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1325 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1342 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2038 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1416 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3479 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1818 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1570 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2159 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1047 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 1.0920 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1481 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1720 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1357 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1354 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2288 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1062 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3497 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1472 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1212 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1580 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2069 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2484 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1265 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1583 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1214 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1255 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4423 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1532 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1830 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3541 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1384 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3921 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3255 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1937 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3129 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4053 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1706 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1454 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4413 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1211 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3932 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1023 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1410 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0884 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1001 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2092 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1359 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6187 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.0841 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1118 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2042 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1286 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2084 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2401 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1145 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2945 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0870 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1422 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1247 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2064 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1579 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2326 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0950 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1355 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1017 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5781 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 1.0058 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1247 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.1429 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1720 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2193 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1481 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1806 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1252 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2348 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1727 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2144 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2735 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1643 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2157 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1777 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0958 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0954 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2085 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1247 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1752 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1481 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.8728 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.2571 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1388 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2132 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3768 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1561 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0973 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1556 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1801 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1384 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1239 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1922 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1432 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1463 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0793 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1769 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0568 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1336 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1810 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3229 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1311 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0908 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1879 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1205 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1451 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1347 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2468 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1703 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1064 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1419 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1841 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1294 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.6373 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0579 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1157 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5482 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1128 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0780 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1416 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0929 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1504 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1595 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1223 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1418 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0992 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1130 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1826 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2058 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4760 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1169 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1659 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1748 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0542 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0805 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1161 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1514 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3257 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0551 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1751 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5790 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1421 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1942 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.7574 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1109 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0993 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1622 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2189 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1896 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1176 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4409 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.9346 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1292 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1991 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3451 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 1.0341 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1629 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1403 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4635 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3905 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1562 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0947 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.7753 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1465 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1737 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3417 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1637 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2274 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3521 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3562 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2865 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1942 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2128 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1330 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2146 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1406 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3162 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2089 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3533 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3659 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2643 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1718 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2228 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1375 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2004 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1283 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1167 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0790 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1260 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2359 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1562 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2219 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4483 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1323 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1054 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4339 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0793 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0945 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1140 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3937 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2308 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.6124 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.1059 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1219 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1212 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1635 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2110 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.4274 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1433 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5562 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1140 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1422 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1022 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1243 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1267 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0554 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1339 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1225 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1764 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1234 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1273 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1488 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1028 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1738 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2104 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1895 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1187 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1343 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2089 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1324 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2460 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.3917 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2135 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1762 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2071 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2660 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0880 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1503 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1307 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1386 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1313 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0653 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.8004 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.3409 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1633 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5129 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1856 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1716 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0440 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0530 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2634 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1310 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1706 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.3900 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0703 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0538 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1318 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1733 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0409 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.3985 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1915 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1623 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1609 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1548 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1353 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.4671 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1321 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0376 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1121 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0717 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1502 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0431 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0396 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0650 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5568 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2134 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.2064 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1641 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.5187 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1072 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0700 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0649 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1431 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1319 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0639 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1173 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.7109 - accuracy: 0.5000\n",
      "1/1 - 0s - loss: 0.0679 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0913 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.2053 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.1893 - accuracy: 0.7500\n",
      "1/1 - 0s - loss: 0.0557 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0728 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1815 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0386 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1086 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.0405 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.1009 - accuracy: 1.0000\n",
      "실젯값 : [0] 예측값 :  [0]\n",
      "실젯값 : [1] 예측값 :  [1]\n",
      "실젯값 : [1] 예측값 :  [1]\n",
      "실젯값 : [1] 예측값 :  [1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, TimeDistributed\n",
    "\n",
    "def get_sequence(n_timesteps):\n",
    "    X = np.array([random() for _ in range(n_timesteps)])\n",
    "    \n",
    "    limit = n_timesteps / 4.0\n",
    "    \n",
    "    y = np.array([0 if x < limit else 1 for x in np.cumsum(X)])\n",
    "    \n",
    "    X = X.reshape(1, n_timesteps, 1)\n",
    "    y = y.reshape(1, n_timesteps, 1)\n",
    "    return X, y\n",
    "\n",
    "n_units = 20\n",
    "n_timesteps = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(n_units, return_sequences=True, input_shape=(n_timesteps, 1))))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for epoch in range(1000):\n",
    "    X, y = get_sequence(n_timesteps)\n",
    "    model.fit(X, y, epochs=1, batch_size=1, verbose=2)\n",
    "    \n",
    "X, y = get_sequence(n_timesteps)\n",
    "yhat = model.predict_classes(X, verbose=0)\n",
    "for i in range(n_timesteps):\n",
    "    print('실젯값 :', y[0, i], '예측값 : ', yhat[0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 크기 : \n",
      " 3555\n",
      "0번째 샘플 문장 시퀀스 : \n",
      " ['한편', ',', 'AFC', '챔피언스', '리그', 'E', '조', '에', '속하', 'ㄴ', '포항', '역시', '대회', '8강', '진출', '이', '불투명', '하', '다', '.']\n",
      "0번째 샘플 bio 태그 : \n",
      " ['O', 'O', 'O', 'O', 'O', 'B_OG', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "샘플 문장 시퀀스 최대 길이 : \n",
      " 168\n",
      "샘플 문장 시퀀스 평균 길이 : \n",
      " 34.03909985935302\n",
      "BIO 태그 사전 크기 : 8\n",
      "단어 사전 크기 : 13834\n",
      "[183, 11, 4276, 884, 162, 931, 402, 10, 2608, 7, 1516, 608, 145, 1361, 414, 4, 6347, 2, 8, 3]\n",
      "[1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "학습 샘플 시퀀스 형상 :  (2844, 40)\n",
      "학습 샘플 레이블 형상 :  (2844, 40, 8)\n",
      "테스트 샘플 시퀀스 형상 :  (711, 40)\n",
      "테스트 샘플 레이블 형상 :  (711, 40, 8)\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 13s 336ms/step - loss: 0.7264 - accuracy: 0.7501\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 8s 333ms/step - loss: 0.2621 - accuracy: 0.8879\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 8s 335ms/step - loss: 0.1662 - accuracy: 0.9227\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 8s 334ms/step - loss: 0.1170 - accuracy: 0.9460\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 8s 335ms/step - loss: 0.0771 - accuracy: 0.9670\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 8s 334ms/step - loss: 0.0544 - accuracy: 0.9773\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.0407 - accuracy: 0.9822\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0319 - accuracy: 0.9860\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0265 - accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0216 - accuracy: 0.9903\n",
      "23/23 [==============================] - 1s 39ms/step - loss: 0.2084 - accuracy: 0.9364\n",
      "평가 결과 :  0.9364340901374817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           _       0.61      0.57      0.59       657\n",
      "         _DT       0.85      0.91      0.88       335\n",
      "         _LC       0.69      0.57      0.62       312\n",
      "         _OG       0.72      0.54      0.62       481\n",
      "         _PS       0.68      0.49      0.57       374\n",
      "         _TI       0.93      0.79      0.85        66\n",
      "\n",
      "   micro avg       0.71      0.61      0.65      2225\n",
      "   macro avg       0.75      0.64      0.69      2225\n",
      "weighted avg       0.70      0.61      0.65      2225\n",
      "\n",
      "F1-score: 65.2%\n",
      "새로운 유형의 시퀀스 :  [531, 307, 1476, 286, 1507, 6766, 1]\n",
      "단어         예측된 NER\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'index_to_her' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-904a1c805370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{:10} {:5}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_to_her\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'index_to_her' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def read_file(file_name):\n",
    "    sents = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for idx, l in enumerate(lines):\n",
    "            if l[0] == ';' and lines[idx + 1][0] == '$':\n",
    "                this_sent = []\n",
    "            elif l[0] == '$' and lines[idx - 1][0] == ';':\n",
    "                continue\n",
    "            elif l[0] == '\\n':\n",
    "                sents.append(this_sent)\n",
    "            else:\n",
    "                this_sent.append(tuple(l.split()))\n",
    "    return sents\n",
    "\n",
    "corpus = read_file('train.txt')\n",
    "\n",
    "sentences, tags = [], []\n",
    "for t in corpus:\n",
    "    tagged_sentence = []\n",
    "    sentence, bio_tag = [], []\n",
    "    for w in t:\n",
    "        tagged_sentence.append((w[1], w[3]))\n",
    "        sentence.append(w[1])\n",
    "        bio_tag.append(w[3])\n",
    "        \n",
    "    sentences.append(sentence)\n",
    "    tags.append(bio_tag)\n",
    "    \n",
    "print(\"샘플 크기 : \\n\", len(sentences))\n",
    "print(\"0번째 샘플 문장 시퀀스 : \\n\", sentences[0])\n",
    "print(\"0번째 샘플 bio 태그 : \\n\", tags[0])\n",
    "print(\"샘플 문장 시퀀스 최대 길이 : \\n\", max(len(l) for l in sentences))\n",
    "print(\"샘플 문장 시퀀스 평균 길이 : \\n\", (sum(map(len, sentences))/len(sentences)))\n",
    "\n",
    "sent_tokenizer = preprocessing.text.Tokenizer(oov_token='OOV')\n",
    "sent_tokenizer.fit_on_texts(sentences)\n",
    "tag_tokenizer = preprocessing.text.Tokenizer(lower=False)\n",
    "tag_tokenizer.fit_on_texts(tags)\n",
    "\n",
    "vocab_size = len(sent_tokenizer.word_index) + 1\n",
    "tag_size = len(tag_tokenizer.word_index) + 1\n",
    "print(\"BIO 태그 사전 크기 :\", tag_size)\n",
    "print(\"단어 사전 크기 :\", vocab_size)\n",
    "\n",
    "x_train = sent_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tag_tokenizer.texts_to_sequences(tags)\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "index_to_word = sent_tokenizer.index_word\n",
    "index_to_ner = tag_tokenizer.index_word\n",
    "index_to_ner[0] = 'PAD'\n",
    "\n",
    "max_len = 40\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, padding='post', maxlen=max_len)\n",
    "y_train = preprocessing.sequence.pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=.2, random_state=0)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=tag_size)\n",
    "\n",
    "print(\"학습 샘플 시퀀스 형상 : \", x_train.shape)\n",
    "print(\"학습 샘플 레이블 형상 : \", y_train.shape)\n",
    "print(\"테스트 샘플 시퀀스 형상 : \", x_test.shape)\n",
    "print(\"테스트 샘플 레이블 형상 : \", y_test.shape)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=30, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "\n",
    "print(\"평가 결과 : \", model.evaluate(x_test, y_test)[1])\n",
    "\n",
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "        temp = []\n",
    "        for pred in sequence:\n",
    "            pred_index = np.argmax(pred)\n",
    "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(temp)\n",
    "    return result\n",
    "\n",
    "y_predicted = model.predict(x_test)\n",
    "pred_tags = sequences_to_tag(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test)\n",
    "\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "print(classification_report(test_tags, pred_tags))\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "\n",
    "word_to_index = sent_tokenizer.word_index\n",
    "new_sentence = '삼성전자 출시 스마트폰 오늘 애플 도전장 내밀다.'.split()\n",
    "new_x = []\n",
    "for w in new_sentence:\n",
    "    try:\n",
    "        new_x.append(word_to_index.get(w, 1))\n",
    "    except KeyError:\n",
    "        new_x.append(word_to_index['OOV'])\n",
    "\n",
    "print(\"새로운 유형의 시퀀스 : \", new_x)\n",
    "new_padded_seqs = preprocessing.sequence.pad_sequences([new_x], padding=\"post\", value=0, maxlen=max_len)\n",
    "\n",
    "p = model.predict(np.array([new_padded_seqs[0]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "\n",
    "print(\"{:10} {:5}\".format(\"단어\", \"예측된 NER\"))\n",
    "print(\"-\" * 50)\n",
    "for w, pred in zip(new_sentence, p[0]):\n",
    "    print(\"{:10} {:5}\".format(w, index_to_her[pred]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
